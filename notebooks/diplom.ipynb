{"cells":[{"cell_type":"markdown","metadata":{},"source":["apt install libgl1-mesa-glx"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy<1.24 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.23.5)\n","Requirement already satisfied: torch in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.2.1)\n","Requirement already satisfied: torchvision in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.17.1)\n","Requirement already satisfied: lap in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.4.0)\n","Requirement already satisfied: onemetric in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.1.2)\n","Requirement already satisfied: loguru in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.7.2)\n","Requirement already satisfied: cython_bbox in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.1.5)\n","Requirement already satisfied: thop in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.1.1.post2209072238)\n","Requirement already satisfied: opencv-python in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (4.9.0.80)\n","Requirement already satisfied: ultralytics in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (8.1.24)\n","Requirement already satisfied: supervision==0.1.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.1.0)\n","Requirement already satisfied: scikit-image in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.22.0)\n","Requirement already satisfied: ninja in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.11.1.1)\n","Requirement already satisfied: tabulate in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.9.0)\n","Requirement already satisfied: tensorboard in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.16.2)\n","Requirement already satisfied: motmetrics in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (1.4.0)\n","Requirement already satisfied: filterpy in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (1.4.5)\n","Requirement already satisfied: h5py in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (3.10.0)\n","Requirement already satisfied: onnx in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (1.15.0)\n","Requirement already satisfied: onnxruntime in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (1.17.1)\n","Requirement already satisfied: onnx-simplifier==0.3.5 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (0.3.5)\n","Requirement already satisfied: ipywidgets in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from -r requirements.txt (line 23)) (8.1.2)\n","Requirement already satisfied: onnxoptimizer>=0.2.5 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from onnx-simplifier==0.3.5->-r requirements.txt (line 22)) (0.3.13)\n","Requirement already satisfied: protobuf>=3.7.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from onnx-simplifier==0.3.5->-r requirements.txt (line 22)) (4.25.3)\n","Requirement already satisfied: filelock in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (4.9.0)\n","Requirement already satisfied: sympy in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (1.12)\n","Requirement already satisfied: networkx in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (3.2.1)\n","Requirement already satisfied: jinja2 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (3.1.3)\n","Requirement already satisfied: fsspec in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (2024.2.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torch->-r requirements.txt (line 2)) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 2)) (12.4.99)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 3)) (10.2.0)\n","Requirement already satisfied: seaborn in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from onemetric->-r requirements.txt (line 5)) (0.13.2)\n","Requirement already satisfied: matplotlib in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from onemetric->-r requirements.txt (line 5)) (3.8.3)\n","Requirement already satisfied: dataclasses-json in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from onemetric->-r requirements.txt (line 5)) (0.6.4)\n","Requirement already satisfied: Cython in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from cython_bbox->-r requirements.txt (line 7)) (3.0.9)\n","Requirement already satisfied: pyyaml>=5.3.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ultralytics->-r requirements.txt (line 10)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ultralytics->-r requirements.txt (line 10)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ultralytics->-r requirements.txt (line 10)) (1.12.0)\n","Requirement already satisfied: tqdm>=4.64.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ultralytics->-r requirements.txt (line 10)) (4.66.2)\n","Requirement already satisfied: psutil in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ultralytics->-r requirements.txt (line 10)) (5.9.0)\n","Requirement already satisfied: py-cpuinfo in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ultralytics->-r requirements.txt (line 10)) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ultralytics->-r requirements.txt (line 10)) (2.2.1)\n","Requirement already satisfied: imageio>=2.27 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 12)) (2.34.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 12)) (2024.2.12)\n","Requirement already satisfied: packaging>=21 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 12)) (23.1)\n","Requirement already satisfied: lazy_loader>=0.3 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 12)) (0.3)\n","Requirement already satisfied: absl-py>=0.4 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 15)) (2.1.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 15)) (1.62.0)\n","Requirement already satisfied: markdown>=2.6.8 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 15)) (3.5.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 15)) (68.2.2)\n","Requirement already satisfied: six>1.9 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 15)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 15)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 15)) (3.0.1)\n","Requirement already satisfied: xmltodict>=0.12.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from motmetrics->-r requirements.txt (line 16)) (0.13.0)\n","Requirement already satisfied: coloredlogs in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from onnxruntime->-r requirements.txt (line 21)) (15.0.1)\n","Requirement already satisfied: flatbuffers in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from onnxruntime->-r requirements.txt (line 21)) (23.5.26)\n","Requirement already satisfied: comm>=0.1.3 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 23)) (0.2.1)\n","Requirement already satisfied: ipython>=6.1.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 23)) (8.20.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 23)) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=4.0.10 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 23)) (4.0.10)\n","Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipywidgets->-r requirements.txt (line 23)) (3.0.10)\n","Requirement already satisfied: decorator in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (0.18.1)\n","Requirement already satisfied: matplotlib-inline in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (0.1.6)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (3.0.43)\n","Requirement already satisfied: pygments>=2.4.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (2.15.1)\n","Requirement already satisfied: stack-data in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (0.2.0)\n","Requirement already satisfied: exceptiongroup in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (1.2.0)\n","Requirement already satisfied: pexpect>4.3 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (4.8.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from matplotlib->onemetric->-r requirements.txt (line 5)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from matplotlib->onemetric->-r requirements.txt (line 5)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from matplotlib->onemetric->-r requirements.txt (line 5)) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from matplotlib->onemetric->-r requirements.txt (line 5)) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from matplotlib->onemetric->-r requirements.txt (line 5)) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from matplotlib->onemetric->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 10)) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 10)) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 10)) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 10)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 10)) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics->-r requirements.txt (line 10)) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 15)) (2.1.3)\n","Requirement already satisfied: humanfriendly>=9.1 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from coloredlogs->onnxruntime->-r requirements.txt (line 21)) (10.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from dataclasses-json->onemetric->-r requirements.txt (line 5)) (3.21.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from dataclasses-json->onemetric->-r requirements.txt (line 5)) (0.9.0)\n","Requirement already satisfied: mpmath>=0.19 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (0.7.0)\n","Requirement already satisfied: wcwidth in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (0.2.5)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->onemetric->-r requirements.txt (line 5)) (1.0.0)\n","Requirement already satisfied: executing in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (0.8.3)\n","Requirement already satisfied: asttokens in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (2.0.5)\n","Requirement already satisfied: pure-eval in /home/kin/anaconda3/envs/diplom/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 23)) (0.2.2)\n"]}],"source":["# !conda install cmake -y\n","!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'ByteTrack' already exists and is not an empty directory.\n","/home/kin/diplom/ByteTrack\n"]}],"source":["!git clone https://github.com/ifzhang/ByteTrack.git\n","%cd ByteTrack"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71123,"status":"ok","timestamp":1709303642562,"user":{"displayName":"kin","userId":"00217082230292738154"},"user_tz":-180},"id":"tdUVXWsY924U","outputId":"1df6c6aa-3c7e-4c78-d1f9-9dd786d71a25"},"outputs":[{"name":"stdout","output_type":"stream","text":["yolox.__version__: 0.1.0\n"]}],"source":["#@title requirements {display-mode:\"form\"}\n","# !pip install -q numpy torch torchvision cython_bbox onemetric loguru lap thop opencv-python ultralytics supervision==0.1.0\n","\n","# workaround related to https://github.com/roboflow/notebooks/issues/80\n","# %sed -i 's/onnx==1.8.1/onnx==1.9.0/g' requirements.txt\n","\n","# !pip install -q -r requirements.txt\n","!pip setup.py develop\n","\n","from IPython import display\n","display.clear_output()\n","\n","import ByteTrack.yolox as yolox\n","print(\"yolox.__version__:\", yolox.__version__)"]},{"cell_type":"markdown","metadata":{"id":"9i4adYGgDcP7"},"source":["# utils"]},{"cell_type":"markdown","metadata":{},"source":["## yolov8_model"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":907,"status":"ok","timestamp":1709303643467,"user":{"displayName":"kin","userId":"00217082230292738154"},"user_tz":-180},"id":"SxqvwvpqDkai","outputId":"7094b56a-83d1-481c-b936-88f8f32a7515"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model summary (fused): 168 layers, 3007208 parameters, 0 gradients, 8.1 GFLOPs\n"]}],"source":["from ultralytics import YOLO\n","\n","\n","MODEL = \"../best1280.pt\"\n","model = YOLO(MODEL)\n","model.fuse()\n","\n","\n","CLASS_NAMES_DICT = model.names\n","CLASS_ID = [0, 1, 2, 3, 4, 5, 6, 7]\n","\n","CLASS_ID_BY_NAME = {\n","    \"chair\": 0,\n","    \"person\": 1,\n","    \"interactive whiteboard\": 2,\n","    \"keyboard\": 3,\n","    \"laptop\": 4,\n","    \"monitor\": 5,\n","    \"pc\": 6,\n","    \"table\": 7,\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## line_counter"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709303643467,"user":{"displayName":"kin","userId":"00217082230292738154"},"user_tz":-180},"id":"dR2kTEAQDsXh"},"outputs":[],"source":["#@title line_counter {display-mode:\"form\"}\n","from supervision.tools.detections import Detections, BoxAnnotator\n","from supervision.geometry.dataclasses import Point, Rect, Vector\n","from typing import List, Dict\n","import numpy as np\n","from supervision.draw.color import Color\n","from supervision.tools.line_counter import LineCounter, LineCounterAnnotator\n","import cv2\n","\n","\n","class CustomLineCounter:\n","    def __init__(self, start: Point, end: Point, classes: List):\n","        self.vector = Vector(start=start, end=end)\n","        self.tracker_state: Dict[str, bool] = {}\n","        self.start = start\n","        self.end = end\n","        self.result_dict = {\n","            # int(class_id): {\"in_count\": int(0), \"out_count\": int(0)}\n","            int(class_id): {\"in\": [], \"out\": []}\n","            for class_id in classes\n","        }\n","        self.parent = None\n","\n","    def update(self, detections: Detections):\n","        for id in detections.class_id:\n","            mask = np.array(\n","                [class_id in [int(id)] for class_id in detections.class_id], dtype=bool\n","            )\n","            filtereddet = detections.filter(mask=mask, inplace=False)\n","\n","            for xyxy, confidence, class_id, tracker_id in filtereddet:\n","                # handle detections with no tracker_id\n","                if tracker_id is None:\n","                    continue\n","\n","                # we check if all four anchors of bbox are on the same side of vector\n","                x1, y1, x2, y2 = xyxy\n","                anchors = [\n","                    Point(x=x1, y=y1),\n","                    Point(x=x1, y=y2),\n","                    Point(x=x2, y=y1),\n","                    Point(x=x2, y=y2),\n","                ]\n","                triggers = [self.vector.is_in(point=anchor) for anchor in anchors]\n","\n","                # detection is partially in and partially out\n","                if len(set(triggers)) == 2:\n","                    continue\n","\n","                tracker_state = triggers[0]\n","                # handle new detection\n","                if tracker_id not in self.tracker_state:\n","                    self.tracker_state[tracker_id] = tracker_state\n","                    continue\n","\n","                # handle detection on the same side of the line\n","                if self.tracker_state.get(tracker_id) == tracker_state:\n","                    continue\n","\n","                self.tracker_state[tracker_id] = tracker_state\n","                if tracker_state:\n","                    # self.result_dict[int(id)][\"in_count\"] += 1\n","                    self.result_dict[int(id)][\"in\"].append(self.parent.get_time_now())\n","                else:\n","                    # self.result_dict[int(id)][\"out_count\"] += 1\n","                    self.result_dict[int(id)][\"out\"].append(self.parent.get_time_now())\n","\n","    def get_result_dict(self) -> dict:\n","        return self.result_dict\n","\n","\n","class CustomLineCounterAnnotator:\n","    def __init__(\n","        self,\n","        thickness: float = 2,\n","        color: Color = Color.white(),\n","        text_thickness: float = 2,\n","        text_color: Color = Color.black(),\n","        text_scale: float = 0.5,\n","        text_offset: float = 1.5,\n","        text_padding: int = 10,\n","        class_name_dict={},\n","        video_info=[],\n","    ):\n","        self.thickness: float = thickness\n","        self.color: Color = color\n","        self.text_thickness: float = text_thickness\n","        self.text_color: Color = text_color\n","        self.text_scale: float = text_scale\n","        self.text_offset: float = text_offset\n","        self.text_padding: int = text_padding\n","        self.class_name_dict = class_name_dict\n","        self.video_info = video_info\n","\n","    def annotate(self, frame: np.ndarray, line_counter: CustomLineCounter) -> np.ndarray:\n","        cv2.line(\n","            frame,\n","            line_counter.vector.start.as_xy_int_tuple(),\n","            line_counter.vector.end.as_xy_int_tuple(),\n","            self.color.as_bgr(),\n","            self.thickness,\n","            lineType=cv2.LINE_AA,\n","            shift=0,\n","        )\n","        cv2.circle(\n","            frame,\n","            line_counter.vector.start.as_xy_int_tuple(),\n","            radius=5,\n","            color=self.text_color.as_bgr(),\n","            thickness=-1,\n","            lineType=cv2.LINE_AA,\n","        )\n","        cv2.circle(\n","            frame,\n","            line_counter.vector.end.as_xy_int_tuple(),\n","            radius=5,\n","            color=self.text_color.as_bgr(),\n","            thickness=-1,\n","            lineType=cv2.LINE_AA,\n","        )\n","\n","        report = \"\"\n","        for key in line_counter.result_dict:\n","            class_name = CLASS_NAMES_DICT[key]\n","            in_count = line_counter.result_dict[key][\"in\"]\n","            out_count = line_counter.result_dict[key][\"out\"]\n","            report += f\" | {class_name}: in {in_count} out {out_count}\"\n","        report += \" |\"\n","\n","        (report_width, report_height), _ = cv2.getTextSize(\n","            report, cv2.FONT_HERSHEY_SIMPLEX, self.text_scale, self.text_thickness\n","        )\n","\n","        report_x = int(((self.video_info.width) - report_width) / 2)\n","        report_y = int((150 + report_height) / 2 - self.text_offset * report_height)\n","\n","        report_background_rect = Rect(\n","            x=report_x,\n","            y=report_y - report_height,\n","            width=report_width,\n","            height=report_height,\n","        ).pad(padding=self.text_padding)\n","\n","        cv2.rectangle(\n","            frame,\n","            report_background_rect.top_left.as_xy_int_tuple(),\n","            report_background_rect.bottom_right.as_xy_int_tuple(),\n","            self.color.as_bgr(),\n","            -1,\n","        )\n","\n","        cv2.putText(\n","            frame,\n","            report,\n","            (report_x, report_y),\n","            cv2.FONT_HERSHEY_SIMPLEX,\n","            self.text_scale,\n","            self.text_color.as_bgr(),\n","            self.text_thickness,\n","            cv2.LINE_AA,\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["## camera"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709303643467,"user":{"displayName":"kin","userId":"00217082230292738154"},"user_tz":-180},"id":"m5TEd-43D1WC"},"outputs":[],"source":["from datetime import datetime\n","\n","\n","class Camera:\n","    def __init__(self, id: int, aud: int, line_counter, line_counter_annotator, video_info, video_path, generator):\n","        self.id = id\n","        self.aud = aud\n","        self.line_counter = line_counter\n","        self.line_counter.parent = self\n","        self.line_counter_annotator = line_counter_annotator\n","        self.video_path = video_path\n","        self.video_info = video_info\n","        self.generator = generator\n","\n","    def get_time_now(self) -> datetime:\n","        return datetime.now()\n","\n","    def track_video(self, target_video_path):\n","        byte_tracker = BYTETracker(BYTETrackerArgs())\n","        box_annotator = BoxAnnotator(\n","            color=ColorPalette(), thickness=2, text_thickness=2, text_scale=1\n","        )\n","\n","        # open target video file\n","        with VideoSink(target_video_path, self.video_info) as sink:\n","            # loop over video frames\n","            for frame in tqdm(self.generator, total=video_info.total_frames):\n","                # model prediction on single frame and conversion to supervision Detections\n","                results = model(frame)\n","                detections = Detections(\n","                    xyxy=results[0].boxes.xyxy.cpu().numpy(),\n","                    confidence=results[0].boxes.conf.cpu().numpy(),\n","                    class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n","                )\n","\n","                # filtering out detections with unwanted classes\n","                mask = np.array(\n","                    [class_id in CLASS_ID for class_id in detections.class_id], dtype=bool\n","                )\n","                detections.filter(mask=mask, inplace=True)\n","\n","                # tracking detections\n","                tracks = byte_tracker.update(\n","                    output_results=detections2boxes(detections=detections),\n","                    img_info=frame.shape,\n","                    img_size=frame.shape,\n","                )\n","\n","                tracker_id = match_detections_with_tracks(\n","                    detections=detections, tracks=tracks\n","                )\n","\n","                detections.tracker_id = np.array(tracker_id)\n","\n","                # filtering out detections without trackers\n","                mask = np.array(\n","                    [tracker_id is not None for tracker_id in detections.tracker_id],\n","                    dtype=bool,\n","                )\n","                detections.filter(mask=mask, inplace=True)\n","                # format custom labels\n","                labels = [\n","                    f\"id{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n","                    for _, confidence, class_id, tracker_id in detections\n","                ]\n","                frame = box_annotator.annotate(\n","                    frame=frame, detections=detections, labels=labels\n","                )\n","\n","                self.line_counter.update(detections=detections)\n","                self.line_counter_annotator.annotate(frame=frame, line_counter=self.line_counter)\n","\n","                sink.write_frame(frame)\n","        return self.line_counter.result_dict\n","\n","    def get_tracker_info(\n","        self,\n","    ) -> dict:\n","        return self.line_counter.get_result_dict()"]},{"cell_type":"markdown","metadata":{},"source":["## tracker"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":458,"status":"ok","timestamp":1709303643923,"user":{"displayName":"kin","userId":"00217082230292738154"},"user_tz":-180},"id":"ifs-6RcIEAP4"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#@title tracker {display-mode:\"form\"}\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#@title tracker {display-mode:\"form\"}\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n","File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/anaconda3/envs/diplom/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/diplom/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#@title tracker {display-mode:\"form\"}\n","import cv2\n","import matplotlib.pyplot as plt\n","import sys\n","import supervision\n","from supervision.draw.color import ColorPalette\n","from supervision.geometry.dataclasses import Point\n","from supervision.video.dataclasses import VideoInfo\n","from supervision.video.source import get_video_frames_generator\n","from supervision.video.sink import VideoSink\n","from supervision.notebook.utils import show_frame_in_notebook\n","from supervision.tools.detections import Detections, BoxAnnotator\n","from supervision.tools.line_counter import LineCounter, LineCounterAnnotator\n","from typing import List\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from yolox.tracker.byte_tracker import BYTETracker, STrack\n","from onemetric.cv.utils.iou import box_iou_batch\n","from dataclasses import dataclass\n","from typing import Dict\n","import cv2\n","import numpy as np\n","from supervision.draw.color import Color\n","from supervision.geometry.dataclasses import Point, Rect, Vector\n","from supervision.tools.detections import Detections\n","\n","\n","class VideoProcessor:\n","    def __init__(\n","        self,\n","        video_path,\n","    ):\n","        self.video_path = video_path\n","        self.video = cv2.VideoCapture(video_path)\n","        self.width = int(self.video.get(cv2.CAP_PROP_FRAME_WIDTH))\n","        self.height = int(self.video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","    def get_frame_by_order(self, frame_number):\n","        self.video.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n","        ret, frame = self.video.read()\n","        if ret:\n","            return frame\n","        else:\n","            return None\n","\n","    def get_width_height(self):\n","        return self.width, self.height\n","\n","\n","@dataclass(frozen=True)\n","class BYTETrackerArgs:\n","    track_thresh: float = 0.25\n","    track_buffer: int = 30\n","    match_thresh: float = 0.8\n","    aspect_ratio_thresh: float = 3.0\n","    min_box_area: float = 1.0\n","    mot20: bool = False\n","\n","\n","# converts Detections into format that can be consumed by match_detections_with_tracks function\n","def detections2boxes(detections: Detections) -> np.ndarray:\n","    return np.hstack((detections.xyxy, detections.confidence[:, np.newaxis]))\n","\n","\n","# converts List[STrack] into format that can be consumed by match_detections_with_tracks function\n","def tracks2boxes(tracks: List[STrack]) -> np.ndarray:\n","    return np.array([track.tlbr for track in tracks], dtype=float)\n","\n","\n","# matches our bounding boxes with predictions\n","def match_detections_with_tracks(\n","    detections: Detections, tracks: List[STrack]\n",") -> Detections:\n","    if not np.any(detections.xyxy) or len(tracks) == 0:\n","        return np.empty((0,))\n","\n","    tracks_boxes = tracks2boxes(tracks=tracks)\n","    iou = box_iou_batch(tracks_boxes, detections.xyxy)\n","    track2detection = np.argmax(iou, axis=1)\n","\n","    tracker_ids = [None] * len(detections)\n","\n","    for tracker_index, detection_index in enumerate(track2detection):\n","        if iou[tracker_index, detection_index] != 0:\n","            tracker_ids[detection_index] = tracks[tracker_index].track_id\n","\n","    return tracker_ids\n","\n","\n","def track_video(\n","    SOURCE_VIDEO_PATH,\n","    LINE_START,\n","    LINE_END,\n","    CLASS_ID,\n","    TARGET_VIDEO_PATH,\n","    CLASS_NAMES_DICT,\n","    model,\n","):\n","    # create BYTETracker instance\n","    byte_tracker = BYTETracker(BYTETrackerArgs())\n","    # create VideoInfo instance\n","    video_info = VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n","    # create frame generator\n","    generator = get_video_frames_generator(SOURCE_VIDEO_PATH)\n","    # create LineCounter instance\n","    line_counter = CustomLineCounter(start=LINE_START, end=LINE_END, classes=CLASS_ID)\n","    # create instance of BoxAnnotator and LineCounterAnnotator\n","    box_annotator = BoxAnnotator(\n","        color=ColorPalette(), thickness=4, text_thickness=4, text_scale=2\n","    )\n","    line_annotator = CustomLineCounterAnnotator(\n","        thickness=4,\n","        text_thickness=1,\n","        text_scale=0.5,\n","        class_name_dict=CLASS_NAMES_DICT,\n","        video_info=video_info,\n","    )\n","\n","    # open target video file\n","    with VideoSink(TARGET_VIDEO_PATH, video_info) as sink:\n","        # loop over video frames\n","        for frame in tqdm(generator, total=video_info.total_frames):\n","            # model prediction on single frame and conversion to supervision Detections\n","            results = model(frame)\n","            detections = Detections(\n","                xyxy=results[0].boxes.xyxy.cpu().numpy(),\n","                confidence=results[0].boxes.conf.cpu().numpy(),\n","                class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n","            )\n","\n","            # filtering out detections with unwanted classes\n","            mask = np.array(\n","                [class_id in CLASS_ID for class_id in detections.class_id], dtype=bool\n","            )\n","            detections.filter(mask=mask, inplace=True)\n","\n","            # tracking detections\n","            tracks = byte_tracker.update(\n","                output_results=detections2boxes(detections=detections),\n","                img_info=frame.shape,\n","                img_size=frame.shape,\n","            )\n","\n","            tracker_id = match_detections_with_tracks(\n","                detections=detections, tracks=tracks\n","            )\n","\n","            detections.tracker_id = np.array(tracker_id)\n","\n","            # filtering out detections without trackers\n","            mask = np.array(\n","                [tracker_id is not None for tracker_id in detections.tracker_id],\n","                dtype=bool,\n","            )\n","            detections.filter(mask=mask, inplace=True)\n","            # format custom labels\n","            labels = [\n","                f\"id{tracker_id} {CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n","                for _, confidence, class_id, tracker_id in detections\n","            ]\n","            frame = box_annotator.annotate(\n","                frame=frame, detections=detections, labels=labels\n","            )\n","\n","            line_counter.update(detections=detections)\n","            line_annotator.annotate(frame=frame, line_counter=line_counter)\n","\n","            sink.write_frame(frame)\n","    return line_counter.result_dict"]},{"cell_type":"markdown","metadata":{"id":"H9PxEHS2EGCf"},"source":["# _"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":5,"status":"error","timestamp":1709303643923,"user":{"displayName":"kin","userId":"00217082230292738154"},"user_tz":-180},"id":"oSrskRgvEgbq","outputId":"c6db700d-d68c-4119-8671-3e008a4a18cb"},"outputs":[],"source":["coords = [[1100, 230],[1200, 750]]\n","video_path = '/home/kin/diplom/test.avi'\n","video_info = VideoInfo.from_video_path(video_path)\n","generator = get_video_frames_generator(video_path)\n","\n","camera = Camera(\n","    id=1,\n","    aud=21,\n","    line_counter=CustomLineCounter(\n","        Point(coords[1][0],coords[1][1]),\n","        Point(coords[0][0],coords[0][1]),\n","        classes=CLASS_ID\n","    ),\n","    line_counter_annotator=CustomLineCounterAnnotator(\n","        class_name_dict=CLASS_NAMES_DICT,\n","        thickness=4,\n","        text_thickness=1,\n","        text_scale=0.5,\n","        video_info=video_info\n","    ),\n","    video_path = video_path,\n","    video_info = video_info,\n","    generator = generator\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1709303643923,"user":{"displayName":"kin","userId":"00217082230292738154"},"user_tz":-180},"id":"7zqy068gCkmp"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa3be875830a4c4382676c2d8f6aa7fc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1817 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 7 tables, 32.1ms\n","Speed: 5.3ms preprocess, 32.1ms inference, 72.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 5 tables, 11.8ms\n","Speed: 4.5ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 6 tables, 9.7ms\n","Speed: 4.8ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 8 tables, 9.0ms\n","Speed: 5.6ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 8 tables, 14.3ms\n","Speed: 5.2ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 8 tables, 14.6ms\n","Speed: 5.3ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 7 tables, 9.8ms\n","Speed: 3.8ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 7 tables, 10.1ms\n","Speed: 4.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.4ms\n","Speed: 3.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.5ms\n","Speed: 4.2ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.5ms\n","Speed: 5.4ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.4ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 12.4ms\n","Speed: 4.8ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.3ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.2ms\n","Speed: 4.0ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 10.5ms\n","Speed: 4.1ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 9.4ms\n","Speed: 3.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.7ms\n","Speed: 4.7ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.2ms\n","Speed: 4.3ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 4 tables, 8.4ms\n","Speed: 5.5ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 4 tables, 9.1ms\n","Speed: 4.4ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 6.8ms\n","Speed: 5.5ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.8ms\n","Speed: 5.2ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.8ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.9ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.1ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.6ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.8ms\n","Speed: 5.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.8ms\n","Speed: 4.4ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.4ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.4ms\n","Speed: 5.1ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.4ms\n","Speed: 4.2ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.5ms\n","Speed: 4.2ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 12.1ms\n","Speed: 6.0ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.0ms\n","Speed: 4.6ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.8ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.4ms\n","Speed: 4.9ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.1ms\n","Speed: 4.5ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 6.5ms\n","Speed: 4.2ms preprocess, 6.5ms inference, 5.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 13.2ms\n","Speed: 5.2ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 9.0ms\n","Speed: 5.0ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.1ms\n","Speed: 4.1ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.4ms\n","Speed: 5.0ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 9.0ms\n","Speed: 4.2ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.8ms\n","Speed: 4.5ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.8ms\n","Speed: 4.2ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.2ms\n","Speed: 4.0ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.2ms\n","Speed: 4.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 9.3ms\n","Speed: 3.8ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.2ms\n","Speed: 4.6ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.9ms\n","Speed: 5.1ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.7ms\n","Speed: 4.2ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.3ms\n","Speed: 5.0ms preprocess, 7.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.3ms\n","Speed: 4.4ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 23.0ms\n","Speed: 14.0ms preprocess, 23.0ms inference, 4.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.7ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.8ms\n","Speed: 5.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.9ms\n","Speed: 4.6ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.1ms\n","Speed: 4.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 6.9ms\n","Speed: 4.8ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 4 tables, 8.0ms\n","Speed: 3.9ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.8ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.7ms\n","Speed: 4.7ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.4ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 4 tables, 8.1ms\n","Speed: 4.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 4 tables, 8.3ms\n","Speed: 4.0ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 4 tables, 7.3ms\n","Speed: 4.5ms preprocess, 7.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 12.8ms\n","Speed: 5.1ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.4ms\n","Speed: 5.2ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.5ms\n","Speed: 5.2ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 11.2ms\n","Speed: 4.8ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.9ms\n","Speed: 4.2ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 9.2ms\n","Speed: 4.7ms preprocess, 9.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 10.6ms\n","Speed: 4.1ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 8 tables, 8.9ms\n","Speed: 4.3ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 9.5ms\n","Speed: 4.3ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 7 tables, 8.4ms\n","Speed: 4.5ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 7 tables, 8.6ms\n","Speed: 4.4ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.7ms\n","Speed: 3.8ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.5ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.3ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.2ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.9ms\n","Speed: 3.9ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.9ms\n","Speed: 3.9ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 7 tables, 8.4ms\n","Speed: 3.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 7 tables, 10.3ms\n","Speed: 4.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.1ms preprocess, 8.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.0ms\n","Speed: 4.5ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 7 tables, 8.6ms\n","Speed: 4.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 7 tables, 8.1ms\n","Speed: 4.4ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 7 tables, 8.3ms\n","Speed: 4.3ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 9.1ms\n","Speed: 5.3ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.0ms\n","Speed: 5.5ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 8 tables, 7.2ms\n","Speed: 5.3ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 8 tables, 7.2ms\n","Speed: 4.9ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 8 tables, 8.3ms\n","Speed: 4.5ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 9 tables, 7.1ms\n","Speed: 4.9ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 8 tables, 7.9ms\n","Speed: 4.3ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 8 tables, 7.1ms\n","Speed: 4.5ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 7 tables, 7.0ms\n","Speed: 4.1ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 7 tables, 7.4ms\n","Speed: 4.9ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 7 tables, 7.5ms\n","Speed: 3.9ms preprocess, 7.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 7 tables, 7.1ms\n","Speed: 4.5ms preprocess, 7.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 7 tables, 8.9ms\n","Speed: 5.2ms preprocess, 8.9ms inference, 3.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 7 tables, 13.5ms\n","Speed: 4.2ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 6 tables, 13.8ms\n","Speed: 4.5ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.5ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 7.5ms\n","Speed: 6.1ms preprocess, 7.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 9.8ms\n","Speed: 5.2ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 10.1ms\n","Speed: 5.2ms preprocess, 10.1ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 persons, 2 monitors, 6 tables, 13.1ms\n","Speed: 4.0ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 12.0ms\n","Speed: 4.4ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.2ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.5ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 6 tables, 7.0ms\n","Speed: 4.8ms preprocess, 7.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.9ms preprocess, 8.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 11.9ms\n","Speed: 6.6ms preprocess, 11.9ms inference, 10.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.1ms\n","Speed: 4.5ms preprocess, 7.1ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.6ms\n","Speed: 5.6ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.1ms\n","Speed: 3.9ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 7.9ms\n","Speed: 4.7ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.1ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.0ms\n","Speed: 4.5ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 9.4ms\n","Speed: 4.1ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 6 tables, 8.4ms\n","Speed: 4.5ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 2 persons, 2 monitors, 5 tables, 8.7ms\n","Speed: 3.9ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.2ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 6 tables, 9.9ms\n","Speed: 3.9ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 6 tables, 8.0ms\n","Speed: 4.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 7 tables, 8.5ms\n","Speed: 4.2ms preprocess, 8.5ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 7 tables, 9.4ms\n","Speed: 4.2ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 9.2ms\n","Speed: 4.2ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 7 tables, 8.3ms\n","Speed: 4.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 6 tables, 9.6ms\n","Speed: 3.7ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 7 tables, 8.3ms\n","Speed: 4.6ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 6 tables, 9.7ms\n","Speed: 4.3ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 6 tables, 9.4ms\n","Speed: 4.3ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 6 tables, 9.5ms\n","Speed: 3.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 8.2ms\n","Speed: 4.6ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 8 tables, 9.5ms\n","Speed: 3.7ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 7.7ms\n","Speed: 4.2ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 8 tables, 9.7ms\n","Speed: 3.7ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 8 tables, 7.2ms\n","Speed: 4.6ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 7.3ms\n","Speed: 3.7ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 7.3ms\n","Speed: 5.0ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 7 tables, 7.3ms\n","Speed: 3.7ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 7 tables, 8.8ms\n","Speed: 4.7ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 8.9ms\n","Speed: 4.9ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 8.7ms\n","Speed: 4.2ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 7 tables, 7.7ms\n","Speed: 3.9ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 7 tables, 8.1ms\n","Speed: 4.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 8 tables, 8.8ms\n","Speed: 8.7ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.5ms\n","Speed: 5.0ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.4ms\n","Speed: 4.5ms preprocess, 7.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.3ms\n","Speed: 3.9ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.8ms\n","Speed: 4.1ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 7.9ms\n","Speed: 3.9ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.9ms\n","Speed: 4.4ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 8 tables, 9.1ms\n","Speed: 4.6ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 8 tables, 7.3ms\n","Speed: 5.2ms preprocess, 7.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 8 tables, 9.0ms\n","Speed: 4.1ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 8.1ms\n","Speed: 5.0ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 8.9ms\n","Speed: 4.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 8.2ms\n","Speed: 4.3ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 7.2ms\n","Speed: 4.8ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 6.7ms\n","Speed: 4.8ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 13.5ms\n","Speed: 4.5ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 10.1ms\n","Speed: 4.3ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 8 tables, 8.6ms\n","Speed: 4.6ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 8.5ms\n","Speed: 4.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.1ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.1ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.9ms\n","Speed: 3.9ms preprocess, 7.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 6.9ms\n","Speed: 4.2ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 24.3ms\n","Speed: 13.6ms preprocess, 24.3ms inference, 4.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 9.2ms\n","Speed: 5.0ms preprocess, 9.2ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.9ms\n","Speed: 4.0ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.8ms\n","Speed: 4.0ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.5ms\n","Speed: 4.7ms preprocess, 7.5ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.2ms\n","Speed: 4.6ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.5ms\n","Speed: 4.3ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 15.1ms\n","Speed: 5.3ms preprocess, 15.1ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.9ms\n","Speed: 4.4ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.8ms\n","Speed: 4.2ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.6ms\n","Speed: 4.5ms preprocess, 7.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 10.4ms\n","Speed: 4.6ms preprocess, 10.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.5ms\n","Speed: 4.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.8ms\n","Speed: 3.8ms preprocess, 7.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 5 tables, 7.5ms\n","Speed: 4.1ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.6ms\n","Speed: 4.0ms preprocess, 8.6ms inference, 12.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.2ms\n","Speed: 4.9ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.5ms\n","Speed: 4.9ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.0ms\n","Speed: 4.7ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.6ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 7 tables, 7.9ms\n","Speed: 5.2ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.8ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 10.0ms\n","Speed: 3.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.5ms\n","Speed: 4.7ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.3ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 9.3ms\n","Speed: 4.5ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.9ms\n","Speed: 4.9ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.5ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.8ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 10.3ms\n","Speed: 6.0ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.0ms\n","Speed: 4.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.4ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.6ms preprocess, 8.8ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.7ms\n","Speed: 4.8ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 7.9ms\n","Speed: 4.8ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 7.9ms\n","Speed: 4.5ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.2ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 3.8ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.3ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 7.4ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.1ms\n","Speed: 4.2ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.0ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.3ms\n","Speed: 4.0ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.0ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.2ms\n","Speed: 4.7ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.0ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.7ms\n","Speed: 3.9ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 16.5ms\n","Speed: 5.1ms preprocess, 16.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.7ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.4ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.5ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 9.5ms\n","Speed: 3.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.1ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.7ms\n","Speed: 5.0ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.6ms\n","Speed: 4.9ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 9.2ms\n","Speed: 5.1ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 10.1ms\n","Speed: 4.7ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 10.4ms\n","Speed: 5.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 10.1ms\n","Speed: 4.5ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 13.1ms\n","Speed: 5.3ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.6ms\n","Speed: 4.6ms preprocess, 7.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 9.4ms\n","Speed: 4.7ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.5ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 10.7ms\n","Speed: 5.8ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.3ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 10.2ms\n","Speed: 4.4ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.5ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.9ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 9.2ms\n","Speed: 3.9ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 9.1ms\n","Speed: 4.1ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.4ms preprocess, 7.7ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 9.3ms\n","Speed: 3.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.8ms\n","Speed: 5.3ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.4ms\n","Speed: 3.8ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 9.0ms\n","Speed: 4.8ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.0ms\n","Speed: 5.3ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.8ms\n","Speed: 5.7ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 12.0ms\n","Speed: 5.5ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.6ms\n","Speed: 4.0ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 9.9ms\n","Speed: 4.0ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.4ms\n","Speed: 4.8ms preprocess, 7.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.6ms\n","Speed: 4.0ms preprocess, 8.6ms inference, 6.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 9.3ms\n","Speed: 4.4ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.5ms\n","Speed: 4.2ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 10.2ms\n","Speed: 4.4ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.6ms\n","Speed: 4.6ms preprocess, 8.6ms inference, 5.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 15.2ms\n","Speed: 4.3ms preprocess, 15.2ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 11.7ms\n","Speed: 5.4ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.9ms\n","Speed: 5.4ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 11.5ms\n","Speed: 5.4ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.6ms\n","Speed: 4.2ms preprocess, 7.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.2ms\n","Speed: 4.2ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.6ms\n","Speed: 6.0ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 10.8ms\n","Speed: 5.0ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.5ms\n","Speed: 4.7ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 12.4ms\n","Speed: 4.5ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.6ms\n","Speed: 5.0ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 11.6ms\n","Speed: 5.2ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.0ms\n","Speed: 6.2ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 11.9ms\n","Speed: 4.5ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 10.0ms\n","Speed: 6.2ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 10.3ms\n","Speed: 4.2ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 9.2ms\n","Speed: 4.4ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.9ms\n","Speed: 4.2ms preprocess, 7.9ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.0ms\n","Speed: 4.9ms preprocess, 7.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 11.6ms\n","Speed: 4.6ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.8ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.3ms\n","Speed: 5.7ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 9.9ms\n","Speed: 5.5ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.8ms\n","Speed: 5.2ms preprocess, 7.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.2ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 23.1ms\n","Speed: 6.0ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 13.9ms\n","Speed: 4.4ms preprocess, 13.9ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.4ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.1ms\n","Speed: 4.0ms preprocess, 8.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.9ms\n","Speed: 4.2ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.5ms\n","Speed: 4.1ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 12.1ms\n","Speed: 5.5ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.6ms\n","Speed: 4.4ms preprocess, 7.6ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 8.8ms\n","Speed: 5.2ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 10.2ms\n","Speed: 5.1ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 6 tables, 7.7ms\n","Speed: 5.6ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.2ms\n","Speed: 5.8ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 11.1ms\n","Speed: 5.0ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 5.0ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.0ms\n","Speed: 4.1ms preprocess, 8.0ms inference, 5.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.1ms\n","Speed: 4.2ms preprocess, 7.1ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.9ms\n","Speed: 3.7ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 10.4ms\n","Speed: 5.0ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.6ms\n","Speed: 5.2ms preprocess, 7.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 11.5ms\n","Speed: 5.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 10.8ms\n","Speed: 4.7ms preprocess, 10.8ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.2ms\n","Speed: 5.4ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 6.9ms\n","Speed: 4.8ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.0ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.6ms\n","Speed: 5.0ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.0ms\n","Speed: 3.8ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.2ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.7ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.1ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.7ms\n","Speed: 4.3ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.6ms\n","Speed: 6.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.1ms\n","Speed: 4.1ms preprocess, 7.1ms inference, 4.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.8ms preprocess, 10.4ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 12.8ms\n","Speed: 4.3ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 14.4ms\n","Speed: 5.0ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.9ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.7ms\n","Speed: 5.6ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 10.9ms\n","Speed: 5.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 6.9ms\n","Speed: 4.3ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.4ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 6.3ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.2ms\n","Speed: 5.7ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 5.3ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 19.9ms\n","Speed: 15.0ms preprocess, 19.9ms inference, 4.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 14.5ms\n","Speed: 4.9ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.2ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.7ms\n","Speed: 6.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.6ms\n","Speed: 4.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 9.2ms\n","Speed: 7.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.9ms\n","Speed: 4.4ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.3ms\n","Speed: 5.5ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.2ms\n","Speed: 5.2ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.2ms\n","Speed: 4.3ms preprocess, 8.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 10.1ms\n","Speed: 3.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.2ms\n","Speed: 4.2ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.4ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.2ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.0ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.0ms\n","Speed: 4.7ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.9ms\n","Speed: 4.4ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.4ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.4ms\n","Speed: 4.5ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.3ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.3ms\n","Speed: 4.0ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.3ms\n","Speed: 5.8ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.6ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.0ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.9ms\n","Speed: 4.4ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.3ms preprocess, 7.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.7ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.7ms\n","Speed: 5.4ms preprocess, 7.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.3ms\n","Speed: 4.0ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.0ms\n","Speed: 4.6ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.7ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.7ms\n","Speed: 4.2ms preprocess, 7.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 10.0ms\n","Speed: 4.6ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.6ms\n","Speed: 4.6ms preprocess, 7.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 12.0ms\n","Speed: 5.0ms preprocess, 12.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.7ms\n","Speed: 4.5ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 11.8ms\n","Speed: 5.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.9ms\n","Speed: 4.6ms preprocess, 7.9ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.6ms\n","Speed: 4.5ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.9ms\n","Speed: 4.2ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.3ms\n","Speed: 4.6ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 20.1ms\n","Speed: 17.1ms preprocess, 20.1ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 3 tables, 11.7ms\n","Speed: 5.6ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 6 tables, 7.8ms\n","Speed: 4.1ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.3ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 8.3ms\n","Speed: 5.0ms preprocess, 8.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 8.8ms\n","Speed: 3.9ms preprocess, 8.8ms inference, 4.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.4ms\n","Speed: 4.8ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 9.0ms\n","Speed: 4.1ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.2ms\n","Speed: 4.1ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.9ms\n","Speed: 4.7ms preprocess, 7.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 8.5ms\n","Speed: 4.3ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 9.6ms\n","Speed: 3.8ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.3ms\n","Speed: 4.7ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.7ms\n","Speed: 4.1ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 9.0ms\n","Speed: 3.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 4 tables, 7.9ms\n","Speed: 4.3ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.4ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.0ms preprocess, 7.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.3ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 11.8ms\n","Speed: 3.9ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.7ms\n","Speed: 5.4ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 5 tables, 10.9ms\n","Speed: 4.4ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 1 person, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.1ms preprocess, 7.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 7.8ms\n","Speed: 4.5ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 8.0ms\n","Speed: 4.2ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 9.5ms\n","Speed: 3.6ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 9.4ms\n","Speed: 3.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 8.0ms\n","Speed: 4.3ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 8.8ms\n","Speed: 4.2ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.5ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.7ms\n","Speed: 5.0ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 8.0ms\n","Speed: 4.2ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.7ms preprocess, 7.8ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 11.2ms\n","Speed: 4.4ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 8.5ms\n","Speed: 4.3ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 8.5ms\n","Speed: 4.0ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.3ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 12.9ms\n","Speed: 16.0ms preprocess, 12.9ms inference, 4.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 9.7ms\n","Speed: 6.7ms preprocess, 9.7ms inference, 7.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.0ms\n","Speed: 4.2ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.1ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 7.4ms\n","Speed: 4.3ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 7.9ms\n","Speed: 4.5ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.3ms\n","Speed: 3.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.8ms\n","Speed: 4.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 12.6ms\n","Speed: 3.7ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.1ms\n","Speed: 4.8ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.4ms\n","Speed: 4.3ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 12.4ms\n","Speed: 5.3ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 13.9ms\n","Speed: 4.5ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.9ms\n","Speed: 4.2ms preprocess, 7.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.8ms\n","Speed: 4.6ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.8ms\n","Speed: 4.2ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.5ms\n","Speed: 4.0ms preprocess, 7.5ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.2ms\n","Speed: 4.7ms preprocess, 7.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.8ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.0ms preprocess, 7.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.3ms\n","Speed: 5.0ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.0ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.4ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.7ms\n","Speed: 5.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.1ms\n","Speed: 4.5ms preprocess, 8.1ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.5ms\n","Speed: 4.3ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.6ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 12.6ms\n","Speed: 4.3ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.0ms\n","Speed: 3.9ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.9ms\n","Speed: 4.3ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.6ms\n","Speed: 4.8ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.2ms\n","Speed: 4.5ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.1ms\n","Speed: 4.0ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.6ms\n","Speed: 4.3ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.6ms\n","Speed: 4.5ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 7.9ms\n","Speed: 4.3ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.5ms\n","Speed: 4.7ms preprocess, 8.5ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.4ms\n","Speed: 4.4ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.4ms\n","Speed: 7.6ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 7.8ms\n","Speed: 4.9ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.4ms\n","Speed: 4.2ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.4ms\n","Speed: 4.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.6ms\n","Speed: 4.3ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.1ms\n","Speed: 4.1ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.5ms\n","Speed: 4.0ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.5ms\n","Speed: 4.2ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.2ms\n","Speed: 4.3ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 7.6ms\n","Speed: 3.9ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.1ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.5ms\n","Speed: 4.3ms preprocess, 7.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.9ms\n","Speed: 4.6ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 7.4ms\n","Speed: 4.3ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 4.6ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 6.9ms\n","Speed: 5.6ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 6.9ms\n","Speed: 4.5ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.9ms\n","Speed: 5.1ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 12.4ms\n","Speed: 4.8ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 12.4ms\n","Speed: 4.8ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 14.5ms\n","Speed: 4.7ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.0ms\n","Speed: 4.5ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.1ms\n","Speed: 4.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.0ms\n","Speed: 4.7ms preprocess, 7.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.3ms\n","Speed: 4.3ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.0ms\n","Speed: 5.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.1ms\n","Speed: 4.7ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.4ms\n","Speed: 5.2ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 5 tables, 8.3ms\n","Speed: 4.0ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 5 tables, 8.3ms\n","Speed: 4.5ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.4ms preprocess, 7.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.8ms\n","Speed: 3.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.2ms\n","Speed: 4.4ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.0ms\n","Speed: 5.5ms preprocess, 9.0ms inference, 8.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.1ms\n","Speed: 6.8ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.7ms\n","Speed: 6.5ms preprocess, 8.7ms inference, 4.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 12.7ms\n","Speed: 6.4ms preprocess, 12.7ms inference, 3.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.3ms\n","Speed: 4.9ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.7ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.8ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.7ms\n","Speed: 4.7ms preprocess, 7.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.8ms\n","Speed: 3.9ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.7ms\n","Speed: 5.2ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 14.5ms\n","Speed: 5.3ms preprocess, 14.5ms inference, 4.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 6.4ms preprocess, 10.4ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 6.2ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.4ms\n","Speed: 5.1ms preprocess, 9.4ms inference, 5.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.5ms\n","Speed: 4.7ms preprocess, 10.5ms inference, 9.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.5ms\n","Speed: 4.5ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.3ms\n","Speed: 4.3ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 6.6ms\n","Speed: 4.6ms preprocess, 6.6ms inference, 5.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 12.5ms\n","Speed: 4.5ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.6ms\n","Speed: 6.5ms preprocess, 7.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.6ms\n","Speed: 5.0ms preprocess, 7.6ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.8ms\n","Speed: 4.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.2ms\n","Speed: 4.6ms preprocess, 10.2ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.7ms\n","Speed: 5.0ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.8ms\n","Speed: 4.2ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 14.2ms\n","Speed: 5.1ms preprocess, 14.2ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.2ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.2ms\n","Speed: 4.2ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.5ms\n","Speed: 7.6ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 15.4ms\n","Speed: 5.3ms preprocess, 15.4ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.6ms\n","Speed: 4.9ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.1ms\n","Speed: 4.2ms preprocess, 8.1ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.5ms\n","Speed: 4.2ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.0ms\n","Speed: 5.0ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.4ms\n","Speed: 5.1ms preprocess, 7.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.2ms\n","Speed: 4.8ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.0ms\n","Speed: 4.7ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.7ms\n","Speed: 4.8ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.2ms\n","Speed: 4.1ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.5ms\n","Speed: 5.4ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.2ms\n","Speed: 4.8ms preprocess, 7.2ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.7ms\n","Speed: 4.4ms preprocess, 8.7ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.0ms\n","Speed: 4.7ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.6ms\n","Speed: 4.5ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.3ms\n","Speed: 4.1ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.9ms\n","Speed: 4.7ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.4ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.7ms\n","Speed: 4.5ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.9ms\n","Speed: 4.3ms preprocess, 6.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.1ms\n","Speed: 4.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.1ms\n","Speed: 4.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.5ms\n","Speed: 4.3ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.3ms\n","Speed: 4.6ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.5ms\n","Speed: 4.2ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.4ms\n","Speed: 4.1ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.5ms\n","Speed: 4.9ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.3ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.0ms\n","Speed: 4.6ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 19.5ms\n","Speed: 6.8ms preprocess, 19.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.2ms\n","Speed: 5.4ms preprocess, 7.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.5ms\n","Speed: 5.6ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.9ms\n","Speed: 4.3ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.1ms\n","Speed: 4.0ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.4ms\n","Speed: 4.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.3ms\n","Speed: 4.2ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 6 tables, 6.9ms\n","Speed: 4.2ms preprocess, 6.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 5 tables, 5.9ms\n","Speed: 3.9ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.0ms\n","Speed: 7.4ms preprocess, 6.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.1ms\n","Speed: 4.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.1ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 6.6ms\n","Speed: 4.4ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.3ms\n","Speed: 4.3ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.5ms\n","Speed: 5.6ms preprocess, 7.5ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 6.5ms\n","Speed: 4.7ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.2ms\n","Speed: 4.6ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.9ms\n","Speed: 4.1ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 6.9ms\n","Speed: 4.1ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.2ms\n","Speed: 11.8ms preprocess, 8.2ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.2ms\n","Speed: 5.0ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 6.5ms\n","Speed: 4.2ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 6.9ms\n","Speed: 4.5ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.8ms\n","Speed: 4.0ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.0ms\n","Speed: 4.2ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 6.6ms\n","Speed: 4.2ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 6.4ms\n","Speed: 4.5ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.1ms\n","Speed: 4.6ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.8ms\n","Speed: 4.5ms preprocess, 9.8ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.8ms\n","Speed: 4.4ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.6ms\n","Speed: 5.4ms preprocess, 11.6ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 5.7ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.9ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.2ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.2ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.5ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.4ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.2ms\n","Speed: 5.1ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.7ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.7ms\n","Speed: 4.6ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.7ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.3ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.0ms\n","Speed: 4.8ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.0ms\n","Speed: 4.6ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.4ms\n","Speed: 4.3ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.3ms\n","Speed: 5.5ms preprocess, 8.3ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 6.4ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 7.6ms\n","Speed: 4.4ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 3.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.5ms\n","Speed: 3.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.3ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.1ms\n","Speed: 3.8ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.2ms\n","Speed: 4.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.3ms\n","Speed: 4.3ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.7ms\n","Speed: 4.1ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.2ms\n","Speed: 4.2ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 13.5ms\n","Speed: 6.3ms preprocess, 13.5ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.4ms\n","Speed: 6.1ms preprocess, 9.4ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.6ms\n","Speed: 4.5ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.7ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 5.1ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.2ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.6ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.6ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 9.0ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.9ms\n","Speed: 4.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 7.2ms\n","Speed: 3.7ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.0ms\n","Speed: 4.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.1ms\n","Speed: 4.5ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.9ms\n","Speed: 4.4ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.9ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.2ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.5ms\n","Speed: 3.9ms preprocess, 9.5ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.8ms\n","Speed: 4.3ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.4ms preprocess, 9.7ms inference, 3.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.9ms\n","Speed: 4.1ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.4ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 5.0ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.3ms\n","Speed: 3.9ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 4.5ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.5ms\n","Speed: 3.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.3ms\n","Speed: 4.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.2ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.6ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.7ms\n","Speed: 6.8ms preprocess, 10.7ms inference, 3.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 5.0ms preprocess, 9.6ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 6.5ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.1ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.6ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.9ms\n","Speed: 4.4ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.5ms\n","Speed: 3.9ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.4ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.4ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.3ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.3ms\n","Speed: 3.7ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.3ms\n","Speed: 4.3ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 13.0ms\n","Speed: 4.6ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.5ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 13.1ms\n","Speed: 4.1ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.7ms\n","Speed: 6.1ms preprocess, 11.7ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.5ms\n","Speed: 4.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.4ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.1ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.3ms\n","Speed: 5.0ms preprocess, 10.3ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.8ms\n","Speed: 5.3ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.5ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.9ms\n","Speed: 4.0ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.9ms\n","Speed: 4.4ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.7ms\n","Speed: 6.2ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 21.7ms\n","Speed: 6.0ms preprocess, 21.7ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.8ms\n","Speed: 4.5ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.1ms\n","Speed: 4.2ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.8ms\n","Speed: 3.8ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.1ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.5ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 6.6ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 5.2ms preprocess, 10.4ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 13.2ms\n","Speed: 4.9ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.9ms\n","Speed: 4.3ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.3ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 13.0ms\n","Speed: 4.2ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.8ms\n","Speed: 4.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.2ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.7ms\n","Speed: 5.6ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.5ms\n","Speed: 4.7ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.3ms\n","Speed: 4.2ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.6ms\n","Speed: 4.1ms preprocess, 11.6ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 13.3ms\n","Speed: 4.2ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.1ms preprocess, 9.6ms inference, 5.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.0ms\n","Speed: 4.2ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.3ms\n","Speed: 3.8ms preprocess, 11.3ms inference, 4.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.5ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.2ms\n","Speed: 4.0ms preprocess, 11.2ms inference, 12.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.7ms\n","Speed: 4.8ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.1ms\n","Speed: 4.5ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.9ms\n","Speed: 4.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.0ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 4.3ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.7ms\n","Speed: 3.8ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.6ms\n","Speed: 4.5ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.6ms\n","Speed: 4.3ms preprocess, 10.6ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.8ms\n","Speed: 4.9ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.4ms\n","Speed: 4.2ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.3ms\n","Speed: 5.3ms preprocess, 10.3ms inference, 3.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.8ms\n","Speed: 5.0ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.6ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.4ms\n","Speed: 4.1ms preprocess, 11.4ms inference, 5.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 12.5ms\n","Speed: 4.7ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.3ms\n","Speed: 5.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.0ms\n","Speed: 5.5ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.6ms\n","Speed: 3.7ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.2ms\n","Speed: 4.8ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.9ms\n","Speed: 3.9ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.0ms\n","Speed: 5.2ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 15.8ms\n","Speed: 5.8ms preprocess, 15.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 12.1ms\n","Speed: 4.8ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 12.0ms\n","Speed: 4.1ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.1ms\n","Speed: 5.0ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.7ms preprocess, 10.2ms inference, 12.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 12.6ms\n","Speed: 9.8ms preprocess, 12.6ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 12.9ms\n","Speed: 4.3ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.2ms\n","Speed: 5.0ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.2ms\n","Speed: 4.6ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.8ms\n","Speed: 5.0ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.5ms\n","Speed: 4.4ms preprocess, 9.5ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.5ms\n","Speed: 5.2ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 12.0ms\n","Speed: 5.1ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.0ms\n","Speed: 5.1ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.8ms\n","Speed: 5.3ms preprocess, 11.8ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.1ms\n","Speed: 4.4ms preprocess, 9.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 12.9ms\n","Speed: 4.7ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.9ms\n","Speed: 5.3ms preprocess, 10.9ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.6ms\n","Speed: 4.2ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.7ms\n","Speed: 5.1ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.1ms\n","Speed: 3.7ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.8ms\n","Speed: 5.2ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.3ms\n","Speed: 4.0ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.3ms\n","Speed: 4.7ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.8ms\n","Speed: 4.0ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.0ms\n","Speed: 4.5ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.0ms\n","Speed: 4.0ms preprocess, 11.0ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.9ms\n","Speed: 4.1ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.1ms\n","Speed: 4.0ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.0ms\n","Speed: 4.2ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.1ms\n","Speed: 9.6ms preprocess, 10.1ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.6ms\n","Speed: 6.1ms preprocess, 11.6ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.4ms\n","Speed: 6.2ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.6ms\n","Speed: 4.5ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.3ms\n","Speed: 4.4ms preprocess, 9.3ms inference, 3.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.6ms\n","Speed: 4.6ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.7ms\n","Speed: 4.5ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.3ms\n","Speed: 3.9ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.5ms\n","Speed: 3.7ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.6ms\n","Speed: 3.9ms preprocess, 10.6ms inference, 4.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.4ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 8.8ms\n","Speed: 4.4ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 10.9ms\n","Speed: 4.1ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 10.5ms\n","Speed: 4.0ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 8.8ms\n","Speed: 4.2ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 9.5ms\n","Speed: 3.9ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.6ms\n","Speed: 4.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.5ms\n","Speed: 6.4ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.8ms\n","Speed: 5.0ms preprocess, 8.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 10.6ms\n","Speed: 6.3ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 11.2ms\n","Speed: 4.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 10.1ms\n","Speed: 5.7ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 8.9ms\n","Speed: 4.4ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.1ms\n","Speed: 4.3ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 24.0ms\n","Speed: 4.2ms preprocess, 24.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.4ms\n","Speed: 4.5ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.9ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.1ms\n","Speed: 4.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 9.8ms\n","Speed: 4.4ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 8.4ms\n","Speed: 4.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 9.2ms\n","Speed: 4.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.1ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 8.5ms\n","Speed: 3.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 10.0ms\n","Speed: 5.1ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.0ms\n","Speed: 5.0ms preprocess, 8.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.8ms\n","Speed: 3.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.2ms\n","Speed: 4.0ms preprocess, 8.2ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 8.3ms\n","Speed: 4.4ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 9.0ms\n","Speed: 3.8ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 9.3ms\n","Speed: 4.6ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 14.4ms\n","Speed: 4.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.6ms\n","Speed: 4.5ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.1ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.7ms\n","Speed: 6.3ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.3ms\n","Speed: 5.2ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.4ms\n","Speed: 4.3ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.4ms\n","Speed: 3.8ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.8ms\n","Speed: 5.4ms preprocess, 7.8ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 16.7ms\n","Speed: 4.7ms preprocess, 16.7ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.9ms\n","Speed: 6.1ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.5ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.0ms\n","Speed: 4.4ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.6ms preprocess, 9.4ms inference, 4.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.8ms\n","Speed: 5.1ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.9ms\n","Speed: 4.4ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.0ms preprocess, 9.1ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.2ms\n","Speed: 4.0ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.7ms\n","Speed: 5.5ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 5.4ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.3ms\n","Speed: 4.6ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.1ms\n","Speed: 5.0ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 4.5ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.9ms\n","Speed: 4.0ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 12.2ms\n","Speed: 5.0ms preprocess, 12.2ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 13.0ms\n","Speed: 3.9ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 12.0ms\n","Speed: 4.0ms preprocess, 12.0ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.7ms\n","Speed: 4.0ms preprocess, 11.7ms inference, 4.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.9ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.4ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 13.4ms\n","Speed: 4.6ms preprocess, 13.4ms inference, 8.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.8ms\n","Speed: 5.2ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 12.1ms\n","Speed: 5.4ms preprocess, 12.1ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.5ms\n","Speed: 5.0ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.7ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.2ms\n","Speed: 4.8ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.4ms\n","Speed: 4.7ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.6ms\n","Speed: 4.4ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 14.0ms\n","Speed: 4.4ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 3.9ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.5ms\n","Speed: 7.6ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.3ms\n","Speed: 4.8ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.7ms\n","Speed: 5.1ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 11.3ms\n","Speed: 5.0ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 9.4ms\n","Speed: 4.4ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.6ms\n","Speed: 4.3ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 10.2ms\n","Speed: 4.2ms preprocess, 10.2ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 11.3ms\n","Speed: 5.3ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 13.3ms\n","Speed: 3.9ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 11.7ms\n","Speed: 3.9ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 14.9ms\n","Speed: 5.1ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 11.8ms\n","Speed: 4.7ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 10.5ms\n","Speed: 4.1ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 10.2ms\n","Speed: 3.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 10.9ms\n","Speed: 13.8ms preprocess, 10.9ms inference, 9.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.9ms\n","Speed: 5.8ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 13.0ms\n","Speed: 6.2ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.7ms\n","Speed: 3.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 10.7ms\n","Speed: 4.9ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 9.8ms\n","Speed: 4.2ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 7 tables, 9.5ms\n","Speed: 4.1ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 7 tables, 10.2ms\n","Speed: 4.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 7 tables, 10.8ms\n","Speed: 4.3ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 11.6ms\n","Speed: 5.0ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 13.3ms\n","Speed: 4.8ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 7 tables, 11.9ms\n","Speed: 4.1ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 7 tables, 10.7ms\n","Speed: 4.5ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 8 tables, 12.2ms\n","Speed: 4.3ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 6 tables, 8.9ms\n","Speed: 7.0ms preprocess, 8.9ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.1ms\n","Speed: 4.2ms preprocess, 11.1ms inference, 5.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 12.4ms\n","Speed: 4.3ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 3.8ms preprocess, 10.4ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.8ms\n","Speed: 4.2ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.0ms\n","Speed: 4.5ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 12.8ms\n","Speed: 4.8ms preprocess, 12.8ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 3.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.2ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 23.1ms\n","Speed: 4.4ms preprocess, 23.1ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.0ms\n","Speed: 4.4ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 8.4ms\n","Speed: 4.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.0ms\n","Speed: 4.1ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.8ms\n","Speed: 4.1ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.5ms\n","Speed: 4.6ms preprocess, 11.5ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.1ms\n","Speed: 3.8ms preprocess, 10.1ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.3ms\n","Speed: 4.8ms preprocess, 10.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 14.4ms\n","Speed: 4.9ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.2ms\n","Speed: 4.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.6ms\n","Speed: 4.2ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.5ms\n","Speed: 4.3ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.7ms\n","Speed: 3.9ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.3ms\n","Speed: 4.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.4ms\n","Speed: 3.9ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.7ms\n","Speed: 4.3ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.4ms\n","Speed: 4.2ms preprocess, 9.4ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.4ms\n","Speed: 5.9ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.4ms\n","Speed: 4.1ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.5ms\n","Speed: 4.6ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 12.7ms\n","Speed: 4.9ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.7ms\n","Speed: 4.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.8ms\n","Speed: 3.7ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.8ms\n","Speed: 4.0ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 12.2ms\n","Speed: 25.3ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 8.5ms\n","Speed: 4.8ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.2ms\n","Speed: 4.0ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.6ms\n","Speed: 4.3ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 12.1ms\n","Speed: 4.5ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 12.9ms\n","Speed: 4.2ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 6 tables, 12.2ms\n","Speed: 4.3ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 13.0ms\n","Speed: 4.4ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.2ms\n","Speed: 4.6ms preprocess, 11.2ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.0ms\n","Speed: 4.1ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 7.7ms\n","Speed: 5.0ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.0ms\n","Speed: 4.7ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 7.8ms\n","Speed: 3.5ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 10.7ms\n","Speed: 4.6ms preprocess, 10.7ms inference, 5.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 11.2ms\n","Speed: 4.0ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 12.1ms\n","Speed: 4.4ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 9.4ms\n","Speed: 4.6ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 7 tables, 10.8ms\n","Speed: 4.8ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 8 tables, 10.5ms\n","Speed: 4.5ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 9.0ms\n","Speed: 4.6ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.1ms\n","Speed: 5.4ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.8ms\n","Speed: 6.0ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.6ms\n","Speed: 4.5ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 11.1ms\n","Speed: 5.0ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 6 tables, 10.3ms\n","Speed: 4.1ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.5ms\n","Speed: 4.4ms preprocess, 10.5ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.7ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.9ms\n","Speed: 5.4ms preprocess, 8.9ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.2ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 5.2ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 4.2ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.9ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 5.0ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 6.0ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 5.7ms preprocess, 9.3ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.3ms\n","Speed: 5.8ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.3ms\n","Speed: 5.9ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 17.5ms\n","Speed: 6.7ms preprocess, 17.5ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 14.9ms\n","Speed: 5.5ms preprocess, 14.9ms inference, 4.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.6ms\n","Speed: 5.5ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.8ms preprocess, 9.1ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 4.4ms preprocess, 9.0ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.8ms\n","Speed: 4.0ms preprocess, 11.8ms inference, 5.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.3ms\n","Speed: 7.7ms preprocess, 11.3ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 13.0ms\n","Speed: 6.3ms preprocess, 13.0ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.3ms\n","Speed: 4.5ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 8.2ms\n","Speed: 4.8ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.6ms\n","Speed: 4.8ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.7ms\n","Speed: 3.9ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 10.2ms\n","Speed: 4.6ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 6 tables, 9.1ms\n","Speed: 5.6ms preprocess, 9.1ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 11.8ms\n","Speed: 4.7ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 12.9ms\n","Speed: 4.5ms preprocess, 12.9ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 12.3ms\n","Speed: 4.4ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 10.9ms\n","Speed: 4.2ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 11.5ms\n","Speed: 4.7ms preprocess, 11.5ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 12.4ms\n","Speed: 4.8ms preprocess, 12.4ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 10.3ms\n","Speed: 4.2ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 10.7ms\n","Speed: 4.2ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 10.4ms\n","Speed: 4.7ms preprocess, 10.4ms inference, 3.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.0ms\n","Speed: 4.1ms preprocess, 9.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.8ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.7ms\n","Speed: 4.9ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.1ms\n","Speed: 4.6ms preprocess, 9.1ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 12.2ms\n","Speed: 5.2ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.1ms\n","Speed: 5.0ms preprocess, 8.1ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 10.0ms\n","Speed: 4.3ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.6ms\n","Speed: 4.2ms preprocess, 8.6ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 11.1ms\n","Speed: 4.0ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 10.0ms\n","Speed: 4.3ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 12.8ms\n","Speed: 4.0ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 18.8ms\n","Speed: 4.4ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 12.9ms\n","Speed: 4.9ms preprocess, 12.9ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.2ms\n","Speed: 4.3ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 10.3ms\n","Speed: 4.6ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.5ms\n","Speed: 4.8ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.0ms\n","Speed: 4.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.3ms\n","Speed: 4.5ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.7ms\n","Speed: 4.5ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 7.8ms\n","Speed: 4.0ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.8ms\n","Speed: 4.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.7ms\n","Speed: 4.0ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.7ms\n","Speed: 3.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.7ms\n","Speed: 4.5ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.1ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 17.6ms\n","Speed: 14.5ms preprocess, 17.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.4ms\n","Speed: 4.5ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.0ms\n","Speed: 5.4ms preprocess, 9.0ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.8ms\n","Speed: 4.6ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.1ms\n","Speed: 4.4ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.7ms\n","Speed: 4.1ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.6ms\n","Speed: 5.5ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.9ms\n","Speed: 4.0ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.8ms\n","Speed: 4.9ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.0ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.0ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.2ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.9ms\n","Speed: 4.8ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.0ms\n","Speed: 5.1ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.5ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.3ms\n","Speed: 4.3ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.8ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 13.5ms\n","Speed: 4.5ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 20.5ms\n","Speed: 14.0ms preprocess, 20.5ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.0ms\n","Speed: 5.6ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 13.9ms\n","Speed: 4.8ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.8ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.0ms\n","Speed: 4.6ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.1ms\n","Speed: 6.9ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 16.8ms\n","Speed: 14.5ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.8ms\n","Speed: 5.5ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.7ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.1ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.3ms\n","Speed: 4.9ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.6ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.5ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.7ms\n","Speed: 5.0ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.3ms\n","Speed: 4.6ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.9ms\n","Speed: 3.7ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.6ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.8ms\n","Speed: 4.6ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.7ms\n","Speed: 4.8ms preprocess, 10.7ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.6ms preprocess, 9.7ms inference, 12.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.6ms\n","Speed: 7.2ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 5.7ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.1ms preprocess, 9.7ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.3ms preprocess, 10.2ms inference, 4.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 13.1ms\n","Speed: 4.7ms preprocess, 13.1ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.3ms\n","Speed: 4.9ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.4ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.8ms\n","Speed: 5.2ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.7ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 3.9ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.4ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.3ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.5ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.3ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.1ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.3ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.2ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.8ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.7ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.2ms\n","Speed: 4.4ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 17.6ms\n","Speed: 7.1ms preprocess, 17.6ms inference, 4.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.6ms\n","Speed: 5.0ms preprocess, 9.6ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.1ms\n","Speed: 5.0ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.0ms\n","Speed: 5.0ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.5ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.9ms\n","Speed: 4.0ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.6ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.5ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.3ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.2ms\n","Speed: 4.5ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.7ms\n","Speed: 5.6ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.1ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.7ms preprocess, 10.2ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.8ms\n","Speed: 3.9ms preprocess, 11.8ms inference, 5.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.2ms\n","Speed: 4.3ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.4ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.8ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.9ms\n","Speed: 3.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.7ms\n","Speed: 4.7ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 19.3ms\n","Speed: 6.0ms preprocess, 19.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.0ms\n","Speed: 5.5ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.7ms preprocess, 9.2ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.5ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.4ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.5ms\n","Speed: 4.2ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.1ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.2ms\n","Speed: 4.3ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.4ms\n","Speed: 4.6ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.3ms preprocess, 9.2ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.5ms\n","Speed: 5.4ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.6ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.1ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.6ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.8ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.7ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.1ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.3ms\n","Speed: 5.4ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.5ms\n","Speed: 4.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.9ms preprocess, 9.8ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 13.1ms\n","Speed: 7.9ms preprocess, 13.1ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.9ms\n","Speed: 5.5ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 5.1ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.5ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.4ms\n","Speed: 5.0ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.7ms\n","Speed: 4.3ms preprocess, 12.7ms inference, 5.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.3ms\n","Speed: 4.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.5ms\n","Speed: 4.7ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.2ms\n","Speed: 4.7ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.7ms\n","Speed: 4.5ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 10.6ms\n","Speed: 7.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 11.5ms\n","Speed: 4.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.9ms\n","Speed: 5.0ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.9ms\n","Speed: 4.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.7ms\n","Speed: 4.3ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 7.9ms\n","Speed: 4.0ms preprocess, 7.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.1ms\n","Speed: 5.6ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.8ms\n","Speed: 4.2ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.9ms\n","Speed: 11.9ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 7.3ms\n","Speed: 4.3ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.1ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.7ms\n","Speed: 4.3ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.6ms\n","Speed: 4.4ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.3ms\n","Speed: 3.7ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.1ms\n","Speed: 4.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.4ms\n","Speed: 3.8ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 8.4ms\n","Speed: 4.1ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 6 tables, 9.5ms\n","Speed: 4.1ms preprocess, 9.5ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.3ms\n","Speed: 5.0ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 16.8ms\n","Speed: 4.4ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.5ms\n","Speed: 4.8ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.7ms\n","Speed: 3.7ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.0ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.6ms\n","Speed: 4.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.4ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.8ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.1ms\n","Speed: 6.2ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.4ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.3ms\n","Speed: 5.2ms preprocess, 9.3ms inference, 3.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.2ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 7.9ms\n","Speed: 4.0ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.3ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.7ms\n","Speed: 4.3ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.2ms\n","Speed: 5.3ms preprocess, 11.2ms inference, 4.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.3ms\n","Speed: 5.3ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.8ms\n","Speed: 6.3ms preprocess, 10.8ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 5.7ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.3ms\n","Speed: 5.2ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.6ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 11.8ms\n","Speed: 5.6ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.3ms\n","Speed: 4.6ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.1ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.9ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.6ms\n","Speed: 4.0ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.2ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.6ms\n","Speed: 4.2ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 14.7ms\n","Speed: 9.3ms preprocess, 14.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 13.1ms\n","Speed: 4.6ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.3ms\n","Speed: 4.6ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.3ms\n","Speed: 4.0ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.8ms\n","Speed: 4.6ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.7ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.7ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 5.3ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 19.5ms\n","Speed: 4.8ms preprocess, 19.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 13.0ms\n","Speed: 4.2ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.3ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.1ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.6ms preprocess, 9.4ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.7ms\n","Speed: 4.3ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.7ms\n","Speed: 4.3ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 12.0ms\n","Speed: 4.0ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.9ms\n","Speed: 4.2ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.6ms\n","Speed: 4.3ms preprocess, 8.6ms inference, 13.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.6ms\n","Speed: 5.4ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.6ms\n","Speed: 5.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.5ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.4ms\n","Speed: 3.8ms preprocess, 9.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.6ms\n","Speed: 4.6ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.3ms\n","Speed: 3.8ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.0ms\n","Speed: 3.9ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.5ms\n","Speed: 4.8ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.5ms\n","Speed: 3.8ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.2ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.9ms\n","Speed: 4.7ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 8.8ms\n","Speed: 3.9ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 monitors, 5 tables, 10.4ms\n","Speed: 7.7ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.0ms\n","Speed: 4.1ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.1ms\n","Speed: 5.1ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.6ms preprocess, 9.3ms inference, 13.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.2ms\n","Speed: 4.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 6.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.9ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.8ms\n","Speed: 4.4ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 3.9ms preprocess, 9.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.5ms\n","Speed: 4.2ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.2ms\n","Speed: 4.4ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.0ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.6ms\n","Speed: 4.4ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 18.7ms\n","Speed: 4.3ms preprocess, 18.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.7ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.7ms\n","Speed: 4.7ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 6 tables, 9.7ms\n","Speed: 4.3ms preprocess, 9.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.8ms\n","Speed: 5.1ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.1ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.7ms\n","Speed: 4.1ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 17.1ms\n","Speed: 4.7ms preprocess, 17.1ms inference, 5.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 7.1ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 4 tables, 10.6ms\n","Speed: 9.0ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.6ms\n","Speed: 4.5ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.5ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.3ms\n","Speed: 3.9ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.6ms\n","Speed: 4.3ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.7ms\n","Speed: 5.0ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.9ms\n","Speed: 4.3ms preprocess, 10.9ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.4ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.0ms\n","Speed: 5.0ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 3.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.1ms\n","Speed: 4.5ms preprocess, 8.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.8ms\n","Speed: 4.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 12.9ms\n","Speed: 4.2ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.1ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.5ms\n","Speed: 4.8ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.7ms\n","Speed: 3.9ms preprocess, 10.7ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.8ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.8ms\n","Speed: 4.2ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 6.5ms preprocess, 9.3ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 5.6ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.2ms\n","Speed: 5.4ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.5ms\n","Speed: 10.0ms preprocess, 10.5ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 5.1ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.4ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.8ms\n","Speed: 4.1ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 5.0ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 19.5ms\n","Speed: 4.6ms preprocess, 19.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 13.4ms\n","Speed: 4.1ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.5ms\n","Speed: 5.4ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.6ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.4ms preprocess, 8.4ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 10.6ms\n","Speed: 4.8ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.3ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 7.6ms\n","Speed: 3.8ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 1 person, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.8ms preprocess, 9.4ms inference, 15.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.7ms\n","Speed: 7.5ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.3ms preprocess, 7.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 11.6ms\n","Speed: 4.1ms preprocess, 11.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 5.2ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.0ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 10.0ms\n","Speed: 3.9ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.1ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 1 person, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.1ms preprocess, 7.8ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.6ms\n","Speed: 4.2ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.7ms\n","Speed: 5.1ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.0ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.7ms\n","Speed: 5.4ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.0ms\n","Speed: 4.6ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.6ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.9ms\n","Speed: 5.2ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.9ms\n","Speed: 4.2ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.9ms\n","Speed: 15.3ms preprocess, 11.9ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.1ms\n","Speed: 5.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.6ms\n","Speed: 4.3ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 7.7ms\n","Speed: 3.9ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.1ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.6ms\n","Speed: 3.9ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.8ms\n","Speed: 6.0ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.3ms\n","Speed: 5.7ms preprocess, 10.3ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.5ms\n","Speed: 4.9ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.9ms\n","Speed: 4.8ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 14.2ms\n","Speed: 4.7ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.8ms\n","Speed: 4.5ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.8ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.2ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.3ms\n","Speed: 4.3ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.3ms\n","Speed: 6.2ms preprocess, 8.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.8ms\n","Speed: 5.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 4.0ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 8.6ms\n","Speed: 3.9ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.8ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.0ms\n","Speed: 4.3ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.5ms\n","Speed: 6.8ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.1ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 7.8ms\n","Speed: 4.0ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 7.6ms\n","Speed: 4.0ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 10.1ms\n","Speed: 4.7ms preprocess, 10.1ms inference, 8.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.8ms\n","Speed: 4.4ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 5 tables, 11.6ms\n","Speed: 4.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.3ms\n","Speed: 3.7ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.7ms\n","Speed: 4.5ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 14.4ms\n","Speed: 5.6ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 23.9ms\n","Speed: 4.5ms preprocess, 23.9ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.3ms\n","Speed: 4.7ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.6ms\n","Speed: 5.0ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.3ms\n","Speed: 4.1ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.5ms\n","Speed: 4.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.9ms\n","Speed: 3.9ms preprocess, 9.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.9ms\n","Speed: 4.6ms preprocess, 10.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.4ms\n","Speed: 3.9ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.6ms\n","Speed: 4.4ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.0ms\n","Speed: 4.2ms preprocess, 9.0ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.4ms\n","Speed: 4.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.8ms\n","Speed: 4.7ms preprocess, 8.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.0ms\n","Speed: 4.0ms preprocess, 12.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.1ms\n","Speed: 4.6ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.6ms\n","Speed: 5.8ms preprocess, 10.6ms inference, 8.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.1ms\n","Speed: 4.7ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.4ms\n","Speed: 4.6ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 16.7ms\n","Speed: 5.7ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.7ms\n","Speed: 5.5ms preprocess, 9.7ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.9ms\n","Speed: 4.3ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.7ms\n","Speed: 7.7ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.9ms\n","Speed: 4.5ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.7ms\n","Speed: 4.7ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.4ms\n","Speed: 5.3ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.2ms\n","Speed: 4.6ms preprocess, 10.2ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.4ms\n","Speed: 4.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.3ms\n","Speed: 4.8ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.9ms\n","Speed: 3.9ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.9ms\n","Speed: 4.6ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.3ms\n","Speed: 4.5ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.1ms\n","Speed: 6.1ms preprocess, 12.1ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.5ms\n","Speed: 4.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.3ms\n","Speed: 5.4ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 14.1ms\n","Speed: 4.6ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 21.0ms\n","Speed: 7.1ms preprocess, 21.0ms inference, 6.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 13.8ms\n","Speed: 5.8ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 14.9ms\n","Speed: 6.5ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.3ms\n","Speed: 4.5ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 14.3ms\n","Speed: 4.6ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 14.5ms\n","Speed: 5.0ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.7ms\n","Speed: 4.9ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.7ms\n","Speed: 3.9ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.3ms\n","Speed: 5.0ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.7ms\n","Speed: 4.5ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.9ms\n","Speed: 4.6ms preprocess, 12.9ms inference, 4.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.0ms\n","Speed: 4.7ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.9ms\n","Speed: 5.1ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 15.1ms\n","Speed: 3.8ms preprocess, 15.1ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 13.1ms\n","Speed: 5.2ms preprocess, 13.1ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 13.4ms\n","Speed: 11.5ms preprocess, 13.4ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.1ms\n","Speed: 9.4ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.9ms\n","Speed: 4.3ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.5ms\n","Speed: 4.3ms preprocess, 11.5ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.8ms\n","Speed: 3.8ms preprocess, 11.8ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.0ms\n","Speed: 5.2ms preprocess, 11.0ms inference, 3.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 14.9ms\n","Speed: 4.6ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.9ms\n","Speed: 12.3ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.0ms\n","Speed: 4.6ms preprocess, 11.0ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.2ms\n","Speed: 5.0ms preprocess, 9.2ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.0ms\n","Speed: 4.7ms preprocess, 9.0ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.5ms\n","Speed: 5.4ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 12.6ms\n","Speed: 4.6ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.3ms\n","Speed: 4.7ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.2ms\n","Speed: 4.4ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.8ms\n","Speed: 4.3ms preprocess, 10.8ms inference, 7.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.5ms\n","Speed: 6.3ms preprocess, 9.5ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.4ms\n","Speed: 5.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.7ms\n","Speed: 3.6ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.0ms\n","Speed: 4.9ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.0ms\n","Speed: 5.1ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.2ms\n","Speed: 5.0ms preprocess, 9.2ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.9ms\n","Speed: 5.0ms preprocess, 11.9ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.2ms\n","Speed: 4.5ms preprocess, 9.2ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.3ms\n","Speed: 3.9ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.1ms\n","Speed: 4.6ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.4ms\n","Speed: 3.8ms preprocess, 11.4ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.6ms\n","Speed: 4.3ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.7ms\n","Speed: 4.1ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.4ms\n","Speed: 4.2ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.2ms\n","Speed: 5.1ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 13.0ms\n","Speed: 4.5ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.8ms\n","Speed: 4.7ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.1ms\n","Speed: 4.4ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.9ms\n","Speed: 4.4ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.1ms\n","Speed: 4.4ms preprocess, 10.1ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.1ms\n","Speed: 3.7ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.9ms\n","Speed: 13.7ms preprocess, 11.9ms inference, 10.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 11.2ms\n","Speed: 7.3ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.9ms\n","Speed: 4.2ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.2ms\n","Speed: 4.0ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.2ms\n","Speed: 4.4ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.2ms\n","Speed: 4.4ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.3ms\n","Speed: 4.1ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.7ms\n","Speed: 3.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.5ms\n","Speed: 4.7ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.5ms\n","Speed: 4.9ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.9ms\n","Speed: 4.6ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.6ms\n","Speed: 4.3ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.2ms\n","Speed: 4.1ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 13.5ms\n","Speed: 4.5ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.2ms\n","Speed: 4.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.6ms\n","Speed: 5.4ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.9ms\n","Speed: 3.8ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.8ms\n","Speed: 5.2ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.3ms\n","Speed: 4.4ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.2ms\n","Speed: 4.9ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 8.3ms\n","Speed: 5.0ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.1ms\n","Speed: 4.2ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.5ms\n","Speed: 3.9ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.1ms\n","Speed: 3.9ms preprocess, 8.1ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.9ms\n","Speed: 4.1ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.3ms\n","Speed: 3.9ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.2ms\n","Speed: 4.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.4ms\n","Speed: 4.8ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.2ms\n","Speed: 4.8ms preprocess, 9.2ms inference, 4.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.3ms\n","Speed: 4.5ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.1ms\n","Speed: 5.9ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.4ms\n","Speed: 3.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.1ms\n","Speed: 4.2ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.5ms\n","Speed: 3.9ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.2ms\n","Speed: 4.7ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.4ms\n","Speed: 5.3ms preprocess, 8.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.9ms\n","Speed: 6.2ms preprocess, 8.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.8ms\n","Speed: 3.7ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.5ms\n","Speed: 4.0ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.8ms\n","Speed: 4.1ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.6ms\n","Speed: 4.6ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 10.7ms\n","Speed: 4.1ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 10.9ms\n","Speed: 5.0ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.9ms\n","Speed: 4.7ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 13.9ms\n","Speed: 5.0ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.1ms\n","Speed: 3.7ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 9.5ms\n","Speed: 4.6ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.8ms\n","Speed: 4.2ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.8ms\n","Speed: 5.0ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 2 tables, 11.0ms\n","Speed: 4.9ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 2 tables, 11.7ms\n","Speed: 4.3ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 2 tables, 11.2ms\n","Speed: 4.1ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 12.6ms\n","Speed: 4.4ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 10.5ms\n","Speed: 4.6ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 2 tables, 10.4ms\n","Speed: 4.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 10.2ms\n","Speed: 3.9ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 2 tables, 11.3ms\n","Speed: 4.6ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 2 tables, 11.5ms\n","Speed: 4.7ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 12.7ms\n","Speed: 4.7ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.7ms\n","Speed: 3.8ms preprocess, 9.7ms inference, 3.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 10.5ms\n","Speed: 12.0ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 2 tables, 8.5ms\n","Speed: 5.4ms preprocess, 8.5ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 2 tables, 10.3ms\n","Speed: 4.0ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 2 tables, 12.0ms\n","Speed: 4.1ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 10.7ms\n","Speed: 4.8ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.7ms\n","Speed: 4.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 4 tables, 9.3ms\n","Speed: 4.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 1 person, 2 monitors, 3 tables, 8.8ms\n","Speed: 4.1ms preprocess, 8.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 3 tables, 11.9ms\n","Speed: 5.7ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 3 tables, 10.9ms\n","Speed: 5.3ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 3 tables, 12.6ms\n","Speed: 4.0ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 3 tables, 10.9ms\n","Speed: 4.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 11.1ms\n","Speed: 4.0ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 10.8ms\n","Speed: 4.7ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 8.1ms\n","Speed: 4.3ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 8.7ms\n","Speed: 4.7ms preprocess, 8.7ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 10.1ms\n","Speed: 4.7ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.2ms\n","Speed: 4.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.4ms\n","Speed: 4.1ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 8.7ms\n","Speed: 3.9ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 8.4ms\n","Speed: 4.5ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 8.6ms\n","Speed: 4.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.8ms\n","Speed: 4.8ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 10.3ms\n","Speed: 4.0ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 8.7ms\n","Speed: 4.2ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.1ms\n","Speed: 4.3ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.1ms\n","Speed: 5.1ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 10.0ms\n","Speed: 3.9ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 8.5ms\n","Speed: 4.3ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 10.4ms\n","Speed: 4.3ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 12.3ms\n","Speed: 15.0ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.3ms\n","Speed: 4.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 8.7ms\n","Speed: 5.0ms preprocess, 8.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.4ms\n","Speed: 3.6ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.7ms\n","Speed: 4.5ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 11.9ms\n","Speed: 4.6ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 8.9ms\n","Speed: 6.2ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 10.8ms\n","Speed: 4.2ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 10.7ms\n","Speed: 5.2ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 11.0ms\n","Speed: 5.4ms preprocess, 11.0ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 10.8ms\n","Speed: 4.2ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.9ms\n","Speed: 4.6ms preprocess, 9.9ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.1ms\n","Speed: 4.8ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 9.5ms\n","Speed: 3.8ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 18.6ms\n","Speed: 4.6ms preprocess, 18.6ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 12.8ms\n","Speed: 4.9ms preprocess, 12.8ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 10.8ms\n","Speed: 4.6ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 13.7ms\n","Speed: 4.1ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 1 person, 2 monitors, 4 tables, 8.5ms\n","Speed: 5.0ms preprocess, 8.5ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 4 tables, 10.4ms\n","Speed: 4.9ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 4 tables, 8.8ms\n","Speed: 4.7ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 4 tables, 8.4ms\n","Speed: 4.9ms preprocess, 8.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 4 tables, 9.2ms\n","Speed: 4.5ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 4 tables, 8.3ms\n","Speed: 4.4ms preprocess, 8.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 4 tables, 9.7ms\n","Speed: 4.5ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 4 tables, 11.3ms\n","Speed: 4.3ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 3 tables, 10.7ms\n","Speed: 4.9ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 3 tables, 9.8ms\n","Speed: 4.4ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 8.7ms\n","Speed: 4.1ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 17.8ms\n","Speed: 6.4ms preprocess, 17.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 8.8ms\n","Speed: 5.9ms preprocess, 8.8ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 9.4ms\n","Speed: 4.3ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 9.8ms\n","Speed: 5.0ms preprocess, 9.8ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 9.5ms\n","Speed: 4.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 8.0ms\n","Speed: 4.1ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 8.3ms\n","Speed: 3.9ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 9.2ms\n","Speed: 4.3ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 8.1ms\n","Speed: 4.1ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 9.2ms\n","Speed: 3.9ms preprocess, 9.2ms inference, 3.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 10.0ms\n","Speed: 3.7ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 7.8ms\n","Speed: 4.4ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 8.4ms\n","Speed: 5.0ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 10.0ms\n","Speed: 3.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 19.1ms\n","Speed: 7.8ms preprocess, 19.1ms inference, 28.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 3 tables, 10.2ms\n","Speed: 5.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 3 tables, 8.7ms\n","Speed: 4.0ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 8.4ms\n","Speed: 4.3ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 7.7ms\n","Speed: 4.5ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 7.8ms\n","Speed: 4.0ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 8.0ms\n","Speed: 5.1ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 9.6ms\n","Speed: 4.3ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 9.4ms\n","Speed: 4.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 3 tables, 10.7ms\n","Speed: 3.9ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 8.8ms\n","Speed: 4.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 10.2ms\n","Speed: 4.4ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 11.7ms\n","Speed: 4.0ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 9.8ms\n","Speed: 4.2ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 22.4ms\n","Speed: 4.4ms preprocess, 22.4ms inference, 7.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 2 tables, 9.2ms\n","Speed: 4.4ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 7.7ms\n","Speed: 4.3ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 10.0ms\n","Speed: 6.0ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.1ms\n","Speed: 5.1ms preprocess, 9.1ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.0ms\n","Speed: 4.4ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 7.8ms\n","Speed: 4.1ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 7.6ms\n","Speed: 4.9ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 8.7ms\n","Speed: 4.5ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.3ms\n","Speed: 4.2ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 11.0ms\n","Speed: 4.1ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 10.3ms\n","Speed: 4.5ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 8.7ms\n","Speed: 4.1ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 8.8ms\n","Speed: 4.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 10.2ms\n","Speed: 4.9ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 10.5ms\n","Speed: 4.4ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 27.4ms\n","Speed: 14.2ms preprocess, 27.4ms inference, 3.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 8.8ms\n","Speed: 7.3ms preprocess, 8.8ms inference, 4.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 7.7ms\n","Speed: 4.1ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 7.6ms\n","Speed: 4.6ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 7.7ms\n","Speed: 4.5ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.7ms\n","Speed: 4.0ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 8.5ms\n","Speed: 4.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 7.8ms\n","Speed: 4.7ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.0ms\n","Speed: 4.3ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 10.3ms\n","Speed: 4.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 10.0ms\n","Speed: 4.3ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.8ms\n","Speed: 4.4ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.5ms\n","Speed: 3.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.0ms\n","Speed: 3.9ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 8.8ms\n","Speed: 3.8ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 7.9ms\n","Speed: 4.3ms preprocess, 7.9ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 7.8ms\n","Speed: 3.8ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 17.5ms\n","Speed: 6.8ms preprocess, 17.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 10.5ms\n","Speed: 4.8ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.4ms\n","Speed: 4.4ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 8.4ms\n","Speed: 4.9ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.0ms\n","Speed: 5.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 11.6ms\n","Speed: 4.6ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 10.8ms\n","Speed: 4.5ms preprocess, 10.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 8.8ms\n","Speed: 4.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 8.2ms\n","Speed: 4.2ms preprocess, 8.2ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 2 tables, 9.2ms\n","Speed: 3.7ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 9.4ms\n","Speed: 3.9ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 8.2ms\n","Speed: 5.1ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 9.7ms\n","Speed: 4.4ms preprocess, 9.7ms inference, 7.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 4 tables, 9.1ms\n","Speed: 6.2ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 4 tables, 8.4ms\n","Speed: 4.7ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 8.3ms\n","Speed: 4.1ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 8.7ms\n","Speed: 5.1ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 8.7ms\n","Speed: 5.5ms preprocess, 8.7ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 10.0ms\n","Speed: 4.0ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 9.7ms\n","Speed: 3.8ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 9.5ms\n","Speed: 4.3ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 9.6ms\n","Speed: 4.4ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 4 tables, 10.6ms\n","Speed: 3.8ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 4 tables, 9.1ms\n","Speed: 4.3ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 4 tables, 11.3ms\n","Speed: 4.4ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 4 tables, 8.5ms\n","Speed: 3.9ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 8.6ms\n","Speed: 4.1ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 8.3ms\n","Speed: 4.4ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 8.5ms\n","Speed: 4.3ms preprocess, 8.5ms inference, 4.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 9.2ms\n","Speed: 4.6ms preprocess, 9.2ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 9.1ms\n","Speed: 5.4ms preprocess, 9.1ms inference, 3.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 13.4ms\n","Speed: 6.1ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 10.5ms\n","Speed: 5.4ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 11.5ms\n","Speed: 5.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 11.4ms\n","Speed: 4.2ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 10.6ms\n","Speed: 4.9ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 9.1ms\n","Speed: 4.8ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 4 tables, 8.7ms\n","Speed: 4.6ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 4 tables, 8.8ms\n","Speed: 3.9ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 4 tables, 9.1ms\n","Speed: 4.3ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 12.0ms\n","Speed: 4.2ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 22.3ms\n","Speed: 7.7ms preprocess, 22.3ms inference, 4.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 10.6ms\n","Speed: 5.2ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 9.0ms\n","Speed: 5.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 9.4ms\n","Speed: 4.3ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 11.7ms\n","Speed: 4.0ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 9.7ms\n","Speed: 4.8ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 12.7ms\n","Speed: 6.3ms preprocess, 12.7ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 10.5ms\n","Speed: 4.3ms preprocess, 10.5ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 9.0ms\n","Speed: 4.1ms preprocess, 9.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 9.9ms\n","Speed: 4.1ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 8.6ms\n","Speed: 4.2ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 11.8ms\n","Speed: 4.2ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 10.7ms\n","Speed: 3.8ms preprocess, 10.7ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 19.1ms\n","Speed: 10.4ms preprocess, 19.1ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 10.1ms\n","Speed: 5.2ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 9.3ms\n","Speed: 4.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 9.5ms\n","Speed: 3.8ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 3 tables, 9.1ms\n","Speed: 4.5ms preprocess, 9.1ms inference, 5.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 10.6ms\n","Speed: 4.0ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 10.4ms\n","Speed: 4.3ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 10.7ms\n","Speed: 4.5ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 10.9ms\n","Speed: 5.5ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 8.9ms\n","Speed: 4.1ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 11.5ms\n","Speed: 4.6ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 10.2ms\n","Speed: 4.0ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 4 tables, 21.2ms\n","Speed: 5.6ms preprocess, 21.2ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 3 tables, 9.1ms\n","Speed: 4.6ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 3 tables, 9.1ms\n","Speed: 4.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 3 tables, 8.9ms\n","Speed: 5.2ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 3 tables, 8.7ms\n","Speed: 5.7ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 3 tables, 10.5ms\n","Speed: 4.3ms preprocess, 10.5ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 2 persons, 2 monitors, 3 tables, 9.8ms\n","Speed: 4.7ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 3 tables, 9.8ms\n","Speed: 5.6ms preprocess, 9.8ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 11.3ms\n","Speed: 4.0ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 8.4ms\n","Speed: 4.0ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 8.3ms\n","Speed: 4.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 11.7ms\n","Speed: 5.3ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 9.5ms\n","Speed: 4.2ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 11.2ms\n","Speed: 4.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 11.7ms\n","Speed: 4.5ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 12.5ms\n","Speed: 3.8ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 10.0ms\n","Speed: 4.9ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 3 tables, 10.3ms\n","Speed: 9.0ms preprocess, 10.3ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 3 tables, 9.3ms\n","Speed: 5.2ms preprocess, 9.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 3 tables, 10.0ms\n","Speed: 4.0ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 3 tables, 9.6ms\n","Speed: 4.3ms preprocess, 9.6ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 3 tables, 11.1ms\n","Speed: 3.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 3 tables, 9.5ms\n","Speed: 5.0ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 2 tables, 11.3ms\n","Speed: 4.3ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 2 tables, 10.1ms\n","Speed: 5.0ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 1 table, 12.0ms\n","Speed: 3.9ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 2 tables, 9.9ms\n","Speed: 4.6ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 2 tables, 10.6ms\n","Speed: 3.9ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 2 tables, 10.7ms\n","Speed: 4.4ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 4 persons, 2 monitors, 2 tables, 8.3ms\n","Speed: 4.5ms preprocess, 8.3ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 4 persons, 2 monitors, 2 tables, 10.2ms\n","Speed: 4.4ms preprocess, 10.2ms inference, 7.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 11.3ms\n","Speed: 6.5ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 2 tables, 9.2ms\n","Speed: 7.0ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 2 tables, 9.4ms\n","Speed: 4.9ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 2 tables, 9.8ms\n","Speed: 4.6ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 11.8ms\n","Speed: 4.6ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 10.6ms\n","Speed: 4.7ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 8.6ms\n","Speed: 4.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 8.7ms\n","Speed: 6.2ms preprocess, 8.7ms inference, 2.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 11.4ms\n","Speed: 5.5ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 8.9ms\n","Speed: 4.6ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 4 persons, 2 monitors, 3 tables, 9.0ms\n","Speed: 4.6ms preprocess, 9.0ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 4 persons, 2 monitors, 3 tables, 8.9ms\n","Speed: 4.2ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 4 persons, 2 monitors, 3 tables, 9.1ms\n","Speed: 5.8ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 4 tables, 30.6ms\n","Speed: 6.0ms preprocess, 30.6ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 3 tables, 10.0ms\n","Speed: 4.7ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 4 persons, 2 monitors, 3 tables, 11.2ms\n","Speed: 4.0ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 4 persons, 2 monitors, 3 tables, 10.9ms\n","Speed: 4.4ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 4 persons, 2 monitors, 3 tables, 10.5ms\n","Speed: 4.8ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 4 tables, 10.1ms\n","Speed: 5.5ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 3 tables, 9.7ms\n","Speed: 5.4ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 3 tables, 9.0ms\n","Speed: 4.2ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 4 tables, 11.5ms\n","Speed: 6.1ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 4 tables, 8.8ms\n","Speed: 4.6ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 4 tables, 11.9ms\n","Speed: 4.0ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 4 tables, 12.4ms\n","Speed: 4.2ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 4 tables, 12.8ms\n","Speed: 4.0ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 4 tables, 11.5ms\n","Speed: 4.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 4 tables, 10.4ms\n","Speed: 4.1ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 4 tables, 11.2ms\n","Speed: 4.1ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 4 tables, 9.5ms\n","Speed: 4.8ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 4 tables, 9.5ms\n","Speed: 4.6ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 4 tables, 9.3ms\n","Speed: 4.3ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 4 tables, 9.5ms\n","Speed: 3.7ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 3 tables, 14.6ms\n","Speed: 4.5ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 3 tables, 12.2ms\n","Speed: 4.9ms preprocess, 12.2ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 3 tables, 9.6ms\n","Speed: 5.0ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 3 tables, 9.7ms\n","Speed: 4.2ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 4 tables, 9.0ms\n","Speed: 4.0ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 4 tables, 10.4ms\n","Speed: 4.0ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 5 tables, 9.0ms\n","Speed: 4.7ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 4 tables, 9.8ms\n","Speed: 4.4ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 4 tables, 7.0ms\n","Speed: 4.0ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 4 tables, 8.8ms\n","Speed: 3.9ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 5 tables, 7.0ms\n","Speed: 4.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 3 persons, 2 monitors, 4 tables, 7.0ms\n","Speed: 4.4ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 9.5ms\n","Speed: 4.2ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 11.2ms\n","Speed: 4.7ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 11.7ms\n","Speed: 4.8ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 8.7ms\n","Speed: 3.9ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 7.0ms\n","Speed: 4.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 8.9ms\n","Speed: 4.5ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 9.1ms\n","Speed: 4.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 7.6ms\n","Speed: 4.1ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 7.0ms\n","Speed: 4.5ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 7.6ms\n","Speed: 3.9ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 9.4ms\n","Speed: 4.5ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 7.7ms\n","Speed: 4.4ms preprocess, 7.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 8.2ms\n","Speed: 5.4ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 9.3ms\n","Speed: 3.9ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 10.7ms\n","Speed: 4.1ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.5ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 5 tables, 7.6ms\n","Speed: 5.2ms preprocess, 7.6ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 4 tables, 8.8ms\n","Speed: 5.2ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 4 tables, 9.5ms\n","Speed: 5.0ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 4 tables, 9.3ms\n","Speed: 3.8ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 4 persons, 2 monitors, 4 tables, 9.9ms\n","Speed: 3.8ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 4 persons, 2 monitors, 4 tables, 9.6ms\n","Speed: 5.1ms preprocess, 9.6ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 5 persons, 2 monitors, 4 tables, 8.1ms\n","Speed: 3.9ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 4 persons, 2 monitors, 4 tables, 8.7ms\n","Speed: 4.3ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 4 persons, 2 monitors, 4 tables, 8.4ms\n","Speed: 4.7ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 6 persons, 2 monitors, 4 tables, 7.2ms\n","Speed: 4.4ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 5 persons, 2 monitors, 4 tables, 9.5ms\n","Speed: 4.2ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 5 persons, 2 monitors, 4 tables, 11.9ms\n","Speed: 4.5ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 5 persons, 2 monitors, 4 tables, 9.3ms\n","Speed: 4.6ms preprocess, 9.3ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 5 tables, 8.2ms\n","Speed: 4.3ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 5 tables, 12.6ms\n","Speed: 10.8ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 4 tables, 9.4ms\n","Speed: 5.8ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 6 persons, 2 monitors, 4 tables, 9.0ms\n","Speed: 4.1ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 6 persons, 2 monitors, 4 tables, 8.2ms\n","Speed: 4.8ms preprocess, 8.2ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 4 tables, 12.9ms\n","Speed: 5.2ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 4 tables, 10.6ms\n","Speed: 4.2ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 5 persons, 2 monitors, 4 tables, 11.3ms\n","Speed: 3.8ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 4 tables, 8.7ms\n","Speed: 4.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 4 tables, 8.9ms\n","Speed: 3.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 6 persons, 2 monitors, 4 tables, 9.1ms\n","Speed: 4.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 4 tables, 9.2ms\n","Speed: 4.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 3 tables, 10.1ms\n","Speed: 4.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 3 tables, 8.9ms\n","Speed: 4.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 3 tables, 11.7ms\n","Speed: 4.2ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 11.9ms\n","Speed: 3.9ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 4 tables, 14.1ms\n","Speed: 7.1ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 5 persons, 2 monitors, 3 tables, 9.6ms\n","Speed: 5.4ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 10.1ms\n","Speed: 5.4ms preprocess, 10.1ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 11.2ms\n","Speed: 4.2ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 8.3ms\n","Speed: 4.8ms preprocess, 8.3ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 13.1ms\n","Speed: 3.8ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 11.8ms\n","Speed: 4.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 13.3ms\n","Speed: 3.9ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 10.3ms\n","Speed: 4.2ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 9.6ms\n","Speed: 4.2ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 9.4ms\n","Speed: 4.8ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 11.0ms\n","Speed: 4.7ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 1 chair, 4 persons, 2 monitors, 3 tables, 9.0ms\n","Speed: 5.6ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 3 tables, 19.3ms\n","Speed: 13.9ms preprocess, 19.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 3 tables, 18.6ms\n","Speed: 6.7ms preprocess, 18.6ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 4 persons, 2 monitors, 3 tables, 12.9ms\n","Speed: 4.4ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 12.9ms\n","Speed: 4.7ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 11.4ms\n","Speed: 4.1ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 11.9ms\n","Speed: 4.6ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 9.9ms\n","Speed: 4.8ms preprocess, 9.9ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 8.3ms\n","Speed: 4.1ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 9.4ms\n","Speed: 4.2ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 9.4ms\n","Speed: 4.9ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 8.6ms\n","Speed: 6.2ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 8.3ms\n","Speed: 4.1ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 10.0ms\n","Speed: 3.8ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 10.0ms\n","Speed: 4.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 8.9ms\n","Speed: 3.7ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 9.0ms\n","Speed: 5.6ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 3 tables, 15.8ms\n","Speed: 4.4ms preprocess, 15.8ms inference, 4.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 8.3ms\n","Speed: 4.5ms preprocess, 8.3ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 11.8ms\n","Speed: 3.7ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 15.0ms\n","Speed: 4.5ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 13.1ms\n","Speed: 4.0ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 10.6ms\n","Speed: 4.4ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 3 tables, 8.4ms\n","Speed: 4.5ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 3 tables, 11.1ms\n","Speed: 4.0ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 13.1ms\n","Speed: 5.0ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 9.0ms\n","Speed: 4.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 12.4ms\n","Speed: 4.2ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 14.7ms\n","Speed: 4.4ms preprocess, 14.7ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 3 persons, 2 monitors, 3 tables, 11.4ms\n","Speed: 4.8ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 3 tables, 20.4ms\n","Speed: 14.0ms preprocess, 20.4ms inference, 4.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 14.2ms\n","Speed: 5.5ms preprocess, 14.2ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 11.0ms\n","Speed: 6.7ms preprocess, 11.0ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 3 tables, 11.8ms\n","Speed: 4.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 3 tables, 13.4ms\n","Speed: 4.4ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 3 tables, 13.6ms\n","Speed: 5.9ms preprocess, 13.6ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 3 tables, 15.3ms\n","Speed: 5.2ms preprocess, 15.3ms inference, 2.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 4 tables, 9.5ms\n","Speed: 5.0ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 4 tables, 8.5ms\n","Speed: 4.8ms preprocess, 8.5ms inference, 3.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 4 tables, 11.7ms\n","Speed: 4.1ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 4 tables, 13.1ms\n","Speed: 4.9ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 4 tables, 11.2ms\n","Speed: 4.6ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 10.4ms\n","Speed: 4.4ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 10.3ms\n","Speed: 8.7ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 8.6ms\n","Speed: 5.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 10.1ms\n","Speed: 3.7ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 8.5ms\n","Speed: 5.3ms preprocess, 8.5ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.3ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 9.4ms\n","Speed: 4.0ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 9.5ms\n","Speed: 4.8ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 9.7ms\n","Speed: 4.6ms preprocess, 9.7ms inference, 3.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 10.7ms\n","Speed: 4.5ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 9.2ms\n","Speed: 4.1ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 9.8ms\n","Speed: 4.2ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 3 persons, 2 monitors, 5 tables, 8.7ms\n","Speed: 4.7ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 10.6ms\n","Speed: 4.5ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 9.5ms\n","Speed: 5.5ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 8.8ms\n","Speed: 5.6ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 11.4ms\n","Speed: 4.7ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 10.2ms\n","Speed: 4.8ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 10.4ms\n","Speed: 5.3ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 9.1ms\n","Speed: 4.7ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 2 chairs, 3 persons, 2 monitors, 5 tables, 10.0ms\n","Speed: 4.2ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.2ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.8ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.4ms preprocess, 8.5ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 5 tables, 8.5ms\n","Speed: 4.5ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 5 tables, 8.4ms\n","Speed: 4.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 5 tables, 11.3ms\n","Speed: 13.1ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 3 persons, 2 monitors, 5 tables, 10.0ms\n","Speed: 5.3ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 5 tables, 8.6ms\n","Speed: 4.1ms preprocess, 8.6ms inference, 3.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 5 tables, 11.4ms\n","Speed: 5.0ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 4 chairs, 2 persons, 2 monitors, 5 tables, 8.9ms\n","Speed: 5.3ms preprocess, 8.9ms inference, 2.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 5 chairs, 2 persons, 2 monitors, 4 tables, 8.7ms\n","Speed: 4.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 5 tables, 9.3ms\n","Speed: 4.9ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 8.9ms\n","Speed: 4.9ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 8.7ms\n","Speed: 4.3ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 8.2ms\n","Speed: 4.0ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 9.5ms\n","Speed: 3.9ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 9.8ms\n","Speed: 4.1ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 9.1ms\n","Speed: 4.1ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 20.0ms\n","Speed: 5.7ms preprocess, 20.0ms inference, 1.8ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 9.0ms\n","Speed: 4.8ms preprocess, 9.0ms inference, 2.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 11.5ms\n","Speed: 4.5ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 10.5ms\n","Speed: 4.6ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 10.1ms\n","Speed: 3.6ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 10.3ms\n","Speed: 6.7ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 9.4ms\n","Speed: 4.5ms preprocess, 9.4ms inference, 2.3ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 8.3ms\n","Speed: 4.2ms preprocess, 8.3ms inference, 2.7ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 9.5ms\n","Speed: 3.8ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 4 tables, 10.2ms\n","Speed: 5.0ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 10.0ms\n","Speed: 6.3ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 736, 1280)\n","\n","0: 736x1280 3 chairs, 2 persons, 2 monitors, 3 tables, 13.4ms\n","Speed: 4.0ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 736, 1280)\n"]},{"data":{"text/plain":["{0: {'in': [], 'out': []},\n"," 1: {'in': [datetime.datetime(2024, 3, 6, 18, 49, 33, 158624),\n","   datetime.datetime(2024, 3, 6, 18, 50, 3, 51491),\n","   datetime.datetime(2024, 3, 6, 18, 50, 14, 530782),\n","   datetime.datetime(2024, 3, 6, 18, 50, 19, 611209),\n","   datetime.datetime(2024, 3, 6, 18, 50, 23, 500274)],\n","  'out': [datetime.datetime(2024, 3, 6, 18, 49, 23, 625019),\n","   datetime.datetime(2024, 3, 6, 18, 49, 26, 762672),\n","   datetime.datetime(2024, 3, 6, 18, 49, 52, 175496),\n","   datetime.datetime(2024, 3, 6, 18, 50, 22, 325926),\n","   datetime.datetime(2024, 3, 6, 18, 50, 24, 894089)]},\n"," 2: {'in': [], 'out': []},\n"," 3: {'in': [], 'out': []},\n"," 4: {'in': [], 'out': []},\n"," 5: {'in': [], 'out': []},\n"," 6: {'in': [], 'out': []},\n"," 7: {'in': [], 'out': [datetime.datetime(2024, 3, 6, 18, 49, 51, 567080)]}}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["camera.track_video('result.mp4')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOH0AAWb0j+7DsIBRroavs0","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
